{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import socket\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from random import randint\n",
    "import random\n",
    "import re\n",
    "import colorsys\n",
    "import math\n",
    "from scipy.spatial import Voronoi\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.path as mpltPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "\n",
    "def sanitize_for_filesystem(input_string, len = 6):\n",
    "    safe_string = re.sub(r'[^a-zA-Z0-9]', '', input_string)\n",
    "    return safe_string[:len]\n",
    "\n",
    "def save_tile_results(res2, save_path, max_tile_cols = 6, divider_width = 4, show=False):\n",
    "    divider_color = (255, 0, 0)  # Divider color in RGB (red in this example)\n",
    "\n",
    "    def calculate_canvas_size(images, max_cols, img_width, img_height, divider_width):\n",
    "        #rows = (len(images) + max_cols - 1) // max_cols\n",
    "        canvas_width = (img_width + divider_width) * min(len(images), max_cols) - divider_width\n",
    "        canvas_height = (img_height * 2 + divider_width) #* rows - divider_width\n",
    "        return canvas_width, canvas_height\n",
    "\n",
    "    image_pairs = []\n",
    "\n",
    "    for result in res2:\n",
    "        img_orig = result.orig_img\n",
    "        img_labeled = result.plot(labels=False, conf=False)\n",
    "        img_orig_pil = Image.fromarray(img_orig)\n",
    "        img_labeled_pil = Image.fromarray(img_labeled)\n",
    "        image_pairs.append((img_orig_pil, img_labeled_pil))\n",
    "\n",
    "    if not image_pairs:\n",
    "        print(\"No images to display.\")\n",
    "    else:\n",
    "        img_width, img_height = image_pairs[0][0].size\n",
    "        canvas_width, canvas_height = calculate_canvas_size(image_pairs, max_tile_cols, img_width, img_height, divider_width)\n",
    "        canvas = Image.new('RGB', (canvas_width, canvas_height), \"white\")\n",
    "        draw = ImageDraw.Draw(canvas)\n",
    "\n",
    "        for i, (img_orig, img_labeled) in enumerate(image_pairs[:max_tile_cols]):\n",
    "            col = i % max_tile_cols; row = i // max_tile_cols\n",
    "            top_left_x = col * (img_width + divider_width); top_left_y = row * (img_height * 2 + divider_width)\n",
    "            canvas.paste(img_orig, (top_left_x, top_left_y))\n",
    "            canvas.paste(img_labeled, (top_left_x, top_left_y + img_height + divider_width))\n",
    "\n",
    "            # if col > 0:\n",
    "            #     draw.line([(1+ top_left_x - divider_width, top_left_y), (1+top_left_x - divider_width, top_left_y + img_height * 2)], fill=divider_color, width=divider_width)\n",
    "            #     draw.line([(0, top_left_y - divider_width), (canvas_width, top_left_y - divider_width)], fill=divider_color, width=divider_width)\n",
    "        if (show): display(canvas)\n",
    "        if (save_path!=\"\"): canvas.save(save_path)\n",
    "\n",
    "def results_toDF(res2, addIDCol = False):\n",
    "    data = []\n",
    "    for result in res2:\n",
    "        boxes = result.boxes\n",
    "        inst = 0\n",
    "        for box in boxes:\n",
    "            x, y, w, h = box.xywh[0].tolist()\n",
    "            inst += 1\n",
    "            data.append({\n",
    "                'Fullpath': result.path,\n",
    "                'Filename' : os.path.basename(result.path),\n",
    "                'Instance' : inst,\n",
    "                'Class': box.cls[0].item(),\n",
    "                'Conf': box.conf[0].item(),\n",
    "                'x': x, 'y': y,\n",
    "                'w': w, 'h': h,\n",
    "                'xc' : x + w/2,\n",
    "                'yc' : y + h/2,\n",
    "                'Circ Area' : (0.858 * w * h)\n",
    "            })\n",
    "    df = pd.DataFrame(data)\n",
    "    if (addIDCol): \n",
    "        df['ID'] = df.groupby('path').cumcount()\n",
    "    return df\n",
    "\n",
    "def results_toCSV(res2, save_path):\n",
    "    df = results_toDF(res2)\n",
    "    df.to_csv(save_path, index=False)\n",
    "\n",
    "def polygon_area(coords):\n",
    "    x = coords[:, 0]; y = coords[:, 1]\n",
    "    i = np.arange(len(x))\n",
    "    # 'shoelace' formula\n",
    "    # return 0.5*np.abs(np.dot(x, np.roll(y, -1)) - np.dot(y, np.roll(x, -1)))\n",
    "    return np.abs(np.sum(x[i-1]*y[i]-x[i]*y[i-1])*0.5)\n",
    "\n",
    "def find_parents(classes, image):\n",
    "    class0_indices = np.where(classes == 0)[0]\n",
    "    class1_indices = np.where(classes == 1)[0]\n",
    "    \n",
    "    class1_centers = image.boxes.xywh[class1_indices]\n",
    "    class0_centers = image.boxes.xywh[class0_indices]\n",
    "    \n",
    "    class1_parents = []\n",
    "    for class1_coord in class1_centers.numpy():\n",
    "                # print(\"the class1 instance: \", class1_coord)\n",
    "                \n",
    "                droplet_x = class1_coord[0]\n",
    "                droplet_y = class1_coord[1]\n",
    "                # print(\"droplet x, y coords: \", droplet_x, droplet_y)\n",
    "                min_distance_from_cells = math.inf\n",
    "                parent_cell_index = 0\n",
    "                for i, class0_coord in enumerate(class0_centers.numpy()):\n",
    "                    # print(\"the class0 instance: \", class0_coord)\n",
    "                    \n",
    "                    cell_x = class0_coord[0]\n",
    "                    cell_y = class0_coord[1]\n",
    "                    # print(\"cell x, y coords: \", cell_x, cell_y)\n",
    "                    point1 = np.array((droplet_x, droplet_y))\n",
    "                    point2 = np.array((cell_x, cell_y))\n",
    "                    dist = np.linalg.norm(point1 - point2)\n",
    "                    # print(\"dist from class0 instance: \", dist)\n",
    "                    if dist < min_distance_from_cells:\n",
    "                        min_distance_from_cells = dist\n",
    "                        parent_cell_index = i\n",
    "                        \n",
    "                # print(\"parent cell index: \", parent_cell_index)        \n",
    "                class1_parents.append(class0_indices[parent_cell_index])\n",
    "    return class1_parents\n",
    "\n",
    "def find_first_file(m_folder, m_contains):\n",
    "    \"\"\"\n",
    "    ok so basically this is looking at each subdirectory (including the current directory) and looking at the files in it\n",
    "    and then checking if m_contains is in each subdirectory\n",
    "    \n",
    "    suggestion: you don't have to do for file in files: if m_contains in file. you can just do if m_contains in files\n",
    "        - file is a string\n",
    "        - m_contains is also a string\n",
    "        - you can just check if m_contains is in the list, files\n",
    "    Oh wait, no. m_contains in file checks if file has the string m_contains as a substring\n",
    "        \n",
    "    so basically this function finds the path of where m_contains is located\n",
    "    actually, this function finds the path of the first file in m_folder that contains the substring m_contains and returns it as a str\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(m_folder):\n",
    "        for file in files:\n",
    "            if m_contains in file:\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "def create_multichannel_array(folder_path):\n",
    "    image_arrays = []\n",
    "    image_names = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg','.bmp','.tif')):\n",
    "                file_path = os.path.join(root, file)\n",
    "                t_img = Image.open(file_path).convert('L')  # Convert to grayscale if not already\n",
    "                t_arr = np.array(t_img)\n",
    "                if t_arr.ndim == 2:  # Ensure the image is grayscale\n",
    "                    image_arrays.append(t_arr)\n",
    "                    image_names.append(file)\n",
    "    \n",
    "    if not image_arrays:\n",
    "        return None  # Or raise an exception if you prefer\n",
    "\n",
    "    # Stack the arrays along a new axis to create a multi-channel array\n",
    "    multi_channel_array = np.stack(image_arrays, axis=-1)\n",
    "    return multi_channel_array, image_names\n",
    "\n",
    "def get_color_by_id(point_region_id, total_ids):\n",
    "    hue = point_region_id / total_ids # Scale the hue by the number of unique IDs, wrapping around the hue circle\n",
    "    saturation = 0.9; value = 0.9  # Keep saturation and value high for bright colors\n",
    "    rgb = colorsys.hsv_to_rgb(hue, saturation, value)\n",
    "    return tuple(int(c * 255) for c in rgb) # Convert to 0-255 scale for RGB colors in PIL\n",
    "\n",
    "def get_vor_boundaries(boxes, ImgIfDesired = None):\n",
    "    points= []; vor_verts = {}\n",
    "    for idx in range(len(boxes)): points.append((boxes[idx][0], boxes[idx][1]))\n",
    "    vor = Voronoi(points)\n",
    "    for point_region_id, region_id in enumerate(vor.point_region): #this is needed to preserve the order\n",
    "        if (-1 not in vor.regions[region_id]):\n",
    "            region_vertices = vor.vertices[vor.regions[region_id]]\n",
    "            vor_verts[point_region_id] = region_vertices.tolist()\n",
    "\n",
    "    vor_verts_list = []; default_triangle_height = 2; default_triangle_base_length = 4\n",
    "    for idx, point in enumerate(points):\n",
    "        if idx in vor_verts:  # Voronoi region exists\n",
    "            vor_verts_list.append(vor_verts[idx])\n",
    "        else:  # Create default triangle for missing regions\n",
    "            bl_vertex = (point[0] - default_triangle_base_length / 2, point[1])\n",
    "            br_vertex = (point[0] + default_triangle_base_length / 2, point[1])\n",
    "            top_vertex = (point[0], point[1] + default_triangle_height)  \n",
    "            vor_verts_list.append([bl_vertex, br_vertex, top_vertex])\n",
    "    \n",
    "    if (ImgIfDesired):\n",
    "        drawV = ImageDraw.Draw(ImgIfDesired)\n",
    "        r = 2  # radius of the points\n",
    "        for point_region_id, point in enumerate(points):\n",
    "            outline_color = get_color_by_id(point_region_id, len(points))\n",
    "            left_up_point = (point[0] - r, point[1] - r)\n",
    "            right_down_point = (point[0] + r, point[1] + r)\n",
    "            if vor_verts.get(point_region_id) and len(vor_verts[point_region_id]) > 0:\n",
    "                polygon_vertices_tuples = [tuple(vertex) for vertex in vor_verts[point_region_id]]\n",
    "                drawV.polygon(polygon_vertices_tuples, width=3, outline=outline_color)\n",
    "            drawV.ellipse([left_up_point, right_down_point], fill=outline_color)\n",
    "\n",
    "        display(imgV)\n",
    "    return vor_verts_list\n",
    "\n",
    "def find_mask_intensities(img_data, image_array, file_name, shift_x = 0, shift_y = 0, include_headers = True, meta_name = \"NA\", tile_name = \"NA\"):\n",
    "    sto = io.StringIO()\n",
    "    sth = ''; d = '\\t'\n",
    "\n",
    "    def bstr_h(sth1):\n",
    "        nonlocal sth\n",
    "        sth += sth1\n",
    "\n",
    "    def bstr_m(st1):\n",
    "        sto.write(st1)\n",
    "\n",
    "    def bstr_m_start():\n",
    "        nonlocal sth, sto\n",
    "        st = sth + '\\r' + sto.getvalue()\n",
    "        sto.close()\n",
    "        sto = io.StringIO()\n",
    "        sto.write(st)\n",
    "\n",
    "    def get_mask(vertices):\n",
    "        polygon_path = mpltPath.Path(vertices) # Create a path object from the vertices\n",
    "        inside_polygon = polygon_path.contains_points(class_points)\n",
    "        mask = inside_polygon.reshape(xx.shape) # Reshape the mask back to the image shape\n",
    "        return mask\n",
    "\n",
    "    width =image_array.shape[1]; height = image_array.shape[0]; channels = image_array.shape[2]\n",
    "    boxes = img_data.boxes.cpu()\n",
    "    img_box_centers = boxes.xywh \n",
    "    img_mask_coords = None if img_data.masks is None else img_data.masks.xy\n",
    "    img_vor_coords = get_vor_boundaries(img_box_centers)\n",
    "\n",
    "    first = include_headers; masks = {}\n",
    "    print(\"width =\",width,\"height =\",height,\"chs =\",channels,\"boxes =\",len(img_box_centers),\"vor =\",len(img_vor_coords))\n",
    "    xx, yy = np.meshgrid(np.arange(width),np.arange(height)) # Create a mesh grid of coordinate values\n",
    "    x_flat = xx.flatten(); y_flat = yy.flatten()\n",
    "    class_points = np.vstack((x_flat, y_flat)).T # Create a list of (x, y) points from the flattened grid\n",
    "    for idx in range(len(img_box_centers)):\n",
    "        if (idx % 250 == 0): print(\"Measuring Intensities\",idx)\n",
    "        bbox_xywh = img_box_centers[idx]\n",
    "        bbox_corners = [[bbox_xywh[0] - bbox_xywh[2], bbox_xywh[1] + bbox_xywh[3]],[bbox_xywh[0] + bbox_xywh[2], bbox_xywh[1] + bbox_xywh[3]] ,[bbox_xywh[0] + bbox_xywh[2], bbox_xywh[1] - bbox_xywh[3]], [bbox_xywh[0] - bbox_xywh[2], bbox_xywh[1] - bbox_xywh[3]]]\n",
    "        vor_corners = img_vor_coords[idx]\n",
    "        polys = { \"box\": bbox_corners, \"poly\": img_mask_coords, \"vor\": vor_corners }\n",
    "        masks = {key: get_mask(value) for key, value in polys.items() if value}\n",
    "\n",
    "        # want to add parentID here\n",
    "        if (first): bstr_h('FileName' + d + 'MetaName' + d + 'TileName' + d + 'ObjectID' + d + 'Class'                      + d + 'Confidence'                  + d + 'cx' + d + 'cy' + d)\n",
    "        bstr_m(             file_name + d + meta_name  + d +  tile_name + d + str(idx)   + d + str(boxes[idx].cls.item()) + d + str(boxes[idx].conf.item()) + d + str(bbox_xywh[0].item() + shift_x) + d + str(bbox_xywh[1].item() + shift_y))\n",
    "\n",
    "        # Look at each mask for each channel\n",
    "        for c in range(channels):\n",
    "            cs = str(c)\n",
    "            for key in masks:\n",
    "                selected_pixels = image_array[:, :, c][masks[key]]\n",
    "                area = len(selected_pixels)\n",
    "                if (first and c==0): bstr_h(key + ' AreaP' + d)\n",
    "                if (c==0): bstr_m(               str(area) + d)\n",
    "\n",
    "                sum = np.sum(selected_pixels)\n",
    "                avg = np.average(selected_pixels)\n",
    "                std = np.std(selected_pixels)\n",
    "                if (first): bstr_h(key + ' Total Intensity wv' + cs + d + key + ' Avg Intensity wv' + cs + d + key + ' Std Intensity wv' + cs + d)\n",
    "                bstr_m(                    str(sum)                 + d + str(avg)                       + d + str(std)                       + d)\n",
    "\n",
    "        if (first): bstr_m_start(); first = False\n",
    "        bstr_m('\\r')\n",
    "    return sto.getvalue()\n",
    "\n",
    "def Predict_OnPartsOfImage(model, original_image_name, full_image_arr_predict, full_image_arr_measure = None, save_path = None, new_w = 256, new_h = 256, \n",
    "                           overlap_amount = 0, fill_edges = False, include_headers = True, meta_name = \"NA\", maxdets = 6666, minconf = 0.25):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (YOLO model): the model used to make predictions\n",
    "        original_image_name (string): this is like the path to the image I think\n",
    "        full_image_arr_predict (numpy array): it's the RGB image created from the TO_DAPI image\n",
    "        full_image_arr_measure (numpy array, optional): _description_. Defaults to None.\n",
    "        save_path (_type_, optional): _description_. Defaults to None.\n",
    "        new_w (int, optional): _description_. Defaults to 256.\n",
    "        new_h (int, optional): _description_. Defaults to 256.\n",
    "        overlap_amount (int, optional): _description_. Defaults to 0.\n",
    "        fill_edges (bool, optional): _description_. Defaults to False.\n",
    "        include_headers (bool, optional): whether to include the first row with the column names or not. we pass First as the bool in the code below. Defaults to True.\n",
    "        meta_name (str, optional): _description_. Defaults to \"NA\".\n",
    "        maxdets (int, optional): _description_. Defaults to 6666.\n",
    "        minconf (float, optional): _description_. Defaults to 0.25.\n",
    "    \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    def get_piece(t_arr, x, y):\n",
    "        piece = t_arr[y:min(y + new_h, t_arr.shape[0]), x:min(x + new_w, t_arr.shape[1])] # Calculate the dimensions of the piece \n",
    "        # actually, I think this just cuts out a piece of the array\n",
    "        # between y and [the minimum between the height of the array and y + new_h (default 256, so basically the height of the slice)] \n",
    "        #   and x and [the minimum between the width and the  ]\n",
    "        \n",
    "        if fill_edges: # Create a new array filled with zeros (black) of the desired final size\n",
    "            filled_piece = np.zeros((new_h, new_w), dtype=t_arr.dtype)\n",
    "            filled_piece[:piece.shape[0], :piece.shape[1]] = piece\n",
    "            piece = filled_piece\n",
    "        return piece\n",
    "            \n",
    "    t_arr = full_image_arr_predict # np array of TO_DAPI image\n",
    "    first = include_headers # whether or not to include column names\n",
    "    st = io.StringIO() # an object for writing strings to\n",
    "    \n",
    "    # t_arr.shape[0] is the number of rows of the array\n",
    "    # ok so by default, willie is splitting the image vertically by 256 pixels\n",
    "    for y in range(0, t_arr.shape[0], new_h - overlap_amount):\n",
    "        \n",
    "        # then we're going through the columns. t_arr.shape[1] is the columns in the array\n",
    "        # we're moving over 256 pixels at a time too\n",
    "        for x in range(0, t_arr.shape[1], new_w - overlap_amount):\n",
    "            piece_pred = get_piece(t_arr, x, y)\n",
    "            piece_meas = get_piece(full_image_arr_measure, x, y) if (full_image_arr_measure is not None) else piece_pred\n",
    "            tilename = str(x) + \",\" + str(y); print(\"Region:\",tilename)\n",
    "            predictions = model.predict(piece_pred, show=False, max_det=maxdets) #minconf\n",
    "            #img_array=predictions[0].plot(labels=False, boxes=True, masks=True); display(Image.fromarray(img_array[..., ::-1]))\n",
    "            st.write(find_mask_intensities(predictions[0], piece_meas, original_image_name, x, y, first, meta_name, tilename))\n",
    "            first = False\n",
    "\n",
    "    strRet = st.getvalue()\n",
    "    if (save_path is not None):\n",
    "        with open(save_path, 'a') as file: file.write(strRet)\n",
    "        st.close()\n",
    "    print(\"Done with File\")\n",
    "    return strRet\n",
    "\n",
    "def work_on_folder(model, SubFolder, PredContains, IncludeHeaders = True, save_path = None, maxdet = 6000):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        model (_type_): _description_\n",
    "        SubFolder (_type_): _description_\n",
    "        PredContains (_type_): _description_\n",
    "        IncludeHeaders (bool, optional): whether or not to include the header. we pass in First as the bool in our example. Defaults to True.\n",
    "        save_path (_type_, optional): _description_. Defaults to None.\n",
    "        maxdet (int, optional): _description_. Defaults to 6000.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    file_pred = find_first_file(SubFolder, PredContains) # so this is a str of the file path\n",
    "    # it's the file path for the image to predict on\n",
    "    \n",
    "    # rn, we're predicting on the images with TO_DAPI in their name, and apparently we're getting one of them from each subfolder\n",
    "    pred_arr = np.array(Image.open(file_pred).convert('RGB'))  # Convert to RGB, creates a numpy.ndarray out of file_pred apparently\n",
    "    # how does it convert it?\n",
    "    \n",
    "    meas_arr, names = create_multichannel_array(SubFolder) # with all the images in the subfolder?\n",
    "    st = Predict_OnPartsOfImage(model, file_pred, pred_arr, meas_arr, None, 553, 553, 0, False, IncludeHeaders, SubFolder, maxdet)\n",
    "    if (save_path is not None): \n",
    "        with open(save_path, 'a') as file: file.write(st)\n",
    "    print(\"Done with Files\")\n",
    "    return st, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a text file in S:\\Phys\\FIV925 XSection\\Datasets\\Creed\\20240406 that's a data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SET1_CROPPED ROI2 ---------------------------------\n",
      "Region: 0,0\n",
      "\n",
      "0: 576x576 1305 Nucs, 30.6ms\n",
      "Speed: 15.0ms preprocess, 30.6ms inference, 10.0ms postprocess per image at shape (1, 3, 576, 576)\n",
      "width = 553 height = 553 chs = 13 boxes = 1305 vor = 1305\n",
      "Measuring Intensities 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(subfolder,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# first_level_subfolders is a list of strings, so subfolder is a string, and this line prints it\u001b[39;00m\n\u001b[0;32m     25\u001b[0m subfolder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(m_folder, subfolder) \u001b[38;5;66;03m# creates a string to contain the path of the subfolder\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m st, names \u001b[38;5;241m=\u001b[39m \u001b[43mwork_on_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_contains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFirst\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# ok so now apparently we're running the work_on_folder function\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# passing m_contains makes work_on_folder create a numpy array of the first image in subfolder_path with m_contains in the name\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# so, we're only looking at images with TO_DAPI in its name\u001b[39;00m\n\u001b[0;32m     29\u001b[0m stio\u001b[38;5;241m.\u001b[39mwrite(st)\n",
      "Cell \u001b[1;32mIn[3], line 315\u001b[0m, in \u001b[0;36mwork_on_folder\u001b[1;34m(model, SubFolder, PredContains, IncludeHeaders, save_path, maxdet)\u001b[0m\n\u001b[0;32m    313\u001b[0m pred_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Image\u001b[38;5;241m.\u001b[39mopen(file_pred)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# Convert to RGB\u001b[39;00m\n\u001b[0;32m    314\u001b[0m meas_arr, names \u001b[38;5;241m=\u001b[39m create_multichannel_array(SubFolder) \u001b[38;5;66;03m# with all the images in the subfolder?\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m st \u001b[38;5;241m=\u001b[39m \u001b[43mPredict_OnPartsOfImage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeas_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m553\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m553\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIncludeHeaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSubFolder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (save_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m): \n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(save_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file: file\u001b[38;5;241m.\u001b[39mwrite(st)\n",
      "Cell \u001b[1;32mIn[3], line 301\u001b[0m, in \u001b[0;36mPredict_OnPartsOfImage\u001b[1;34m(model, original_image_name, full_image_arr_predict, full_image_arr_measure, save_path, new_w, new_h, overlap_amount, fill_edges, include_headers, meta_name, maxdets, minconf)\u001b[0m\n\u001b[0;32m    299\u001b[0m         predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(piece_pred, show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, max_det\u001b[38;5;241m=\u001b[39mmaxdets) \u001b[38;5;66;03m#minconf\u001b[39;00m\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m#img_array=predictions[0].plot(labels=False, boxes=True, masks=True); display(Image.fromarray(img_array[..., ::-1]))\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m         st\u001b[38;5;241m.\u001b[39mwrite(\u001b[43mfind_mask_intensities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpiece_meas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moriginal_image_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtilename\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    302\u001b[0m         first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    304\u001b[0m strRet \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "Cell \u001b[1;32mIn[3], line 236\u001b[0m, in \u001b[0;36mfind_mask_intensities\u001b[1;34m(img_data, image_array, file_name, shift_x, shift_y, include_headers, meta_name, tile_name)\u001b[0m\n\u001b[0;32m    234\u001b[0m vor_corners \u001b[38;5;241m=\u001b[39m img_vor_coords[idx]\n\u001b[0;32m    235\u001b[0m polys \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m\"\u001b[39m: bbox_corners, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m\"\u001b[39m: img_mask_coords, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvor\u001b[39m\u001b[38;5;124m\"\u001b[39m: vor_corners }\n\u001b[1;32m--> 236\u001b[0m masks \u001b[38;5;241m=\u001b[39m {key: get_mask(value) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m polys\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m value}\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# want to add parentID here\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (first): bstr_h(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFileName\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetaName\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTileName\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObjectID\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m                      \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfidence\u001b[39m\u001b[38;5;124m'\u001b[39m                  \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d)\n",
      "Cell \u001b[1;32mIn[3], line 236\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    234\u001b[0m vor_corners \u001b[38;5;241m=\u001b[39m img_vor_coords[idx]\n\u001b[0;32m    235\u001b[0m polys \u001b[38;5;241m=\u001b[39m { \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbox\u001b[39m\u001b[38;5;124m\"\u001b[39m: bbox_corners, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpoly\u001b[39m\u001b[38;5;124m\"\u001b[39m: img_mask_coords, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvor\u001b[39m\u001b[38;5;124m\"\u001b[39m: vor_corners }\n\u001b[1;32m--> 236\u001b[0m masks \u001b[38;5;241m=\u001b[39m {key: \u001b[43mget_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m polys\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m value}\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# want to add parentID here\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (first): bstr_h(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFileName\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetaName\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTileName\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObjectID\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClass\u001b[39m\u001b[38;5;124m'\u001b[39m                      \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfidence\u001b[39m\u001b[38;5;124m'\u001b[39m                  \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcx\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m d)\n",
      "Cell \u001b[1;32mIn[3], line 215\u001b[0m, in \u001b[0;36mfind_mask_intensities.<locals>.get_mask\u001b[1;34m(vertices)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mask\u001b[39m(vertices):\n\u001b[0;32m    214\u001b[0m     polygon_path \u001b[38;5;241m=\u001b[39m mpltPath\u001b[38;5;241m.\u001b[39mPath(vertices) \u001b[38;5;66;03m# Create a path object from the vertices\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m     inside_polygon \u001b[38;5;241m=\u001b[39m \u001b[43mpolygon_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclass_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     mask \u001b[38;5;241m=\u001b[39m inside_polygon\u001b[38;5;241m.\u001b[39mreshape(xx\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;66;03m# Reshape the mask back to the image shape\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n",
      "File \u001b[1;32mc:\\Users\\FIVE\\anaconda3\\envs\\torch01\\lib\\site-packages\\matplotlib\\path.py:594\u001b[0m, in \u001b[0;36mPath.contains_points\u001b[1;34m(self, points, transform, radius)\u001b[0m\n\u001b[0;32m    592\u001b[0m     transform \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mfrozen()\n\u001b[0;32m    593\u001b[0m result \u001b[38;5;241m=\u001b[39m _path\u001b[38;5;241m.\u001b[39mpoints_in_path(points, radius, \u001b[38;5;28mself\u001b[39m, transform)\n\u001b[1;32m--> 594\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbool\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# variables\n",
    "model_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Creed\\01a\\YO 553 0328 MAXI\\map75=0296662 yolov9c  idx=1 ep=8 btch=16 rnd=4717152\\weights\\best.pt\"\n",
    "m_folder = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Creed\\20240406\"\n",
    "m_contains = \"T0_DAPI\"\n",
    "res_append = \"2\"\n",
    "\n",
    "model = YOLO(model_path) \n",
    "\n",
    "\"\"\"\n",
    "what is os.walk(m_folder)?\n",
    "    ok idk, it's like a generator object, whatever that means\n",
    "    but next(os.walk(m_folder)) is a tuple where:\n",
    "        - next(os.walk(m_folder))[0] is a folder name\n",
    "        - next(os.walk(m_folder))[1] is a list of subdirectories in the folder\n",
    "        - next(os.walk(m_folder))[2] is another list, but it's of the files in the directory that aren't folders\n",
    "\"\"\"\n",
    "first_level_subfolders = next(os.walk(m_folder))[1]  # Get first level of folders only\n",
    "First = True # ok this must make it so that they're saving out the header\n",
    "stio = io.StringIO() # an object to write strings to\n",
    "namedict = {} # initializing dict I guess\n",
    "\n",
    "# for loop\n",
    "for subfolder in first_level_subfolders: # for each subfolder in the list of subfolders in m_folder\n",
    "    print(subfolder,\"---------------------------------\") # first_level_subfolders is a list of strings, so subfolder is a string, and this line prints it\n",
    "    subfolder_path = os.path.join(m_folder, subfolder) # creates a string to contain the path of the subfolder\n",
    "    st, names = work_on_folder(model, subfolder_path, m_contains, First) # ok so now apparently we're running the work_on_folder function\n",
    "    # passing m_contains makes work_on_folder create a numpy array of the first image in subfolder_path with m_contains in the name\n",
    "    # so, we're only looking at images with TO_DAPI in its name\n",
    "    stio.write(st)\n",
    "    namedict[subfolder] = names\n",
    "    First = False\n",
    "\n",
    "# Save out the main data\n",
    "save_path = os.path.join(m_folder, \"Res00\"+res_append+\".txt\")\n",
    "strRet = stio.getvalue(); stio.close()\n",
    "with open(save_path, 'a') as file: file.write(strRet)\n",
    "\n",
    "# Now save out the name information\n",
    "save_path = os.path.join(m_folder, \"Res00\"+res_append+\"_Names.txt\")\n",
    "rows = [f\"{subfolder}\\t{idx}\\t{name}\" for subfolder, names in namedict.items() for idx, name in enumerate(names)]\n",
    "with open(save_path, 'w') as txtfile:\n",
    "    txtfile.write(\"Subfolder\\tIndex\\tName\\n\") \n",
    "    txtfile.write(\"\\n\".join(rows))\n",
    "\n",
    "print(\"Done with Folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
