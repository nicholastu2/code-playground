{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>FIV942 Image Segmentation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.path as mpltPath\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import matplotlib.colors as mcolors\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train YOLO segment model on data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(r\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h9\\YO 512 0306 Yeti\\map75=0627829 idx=17 ep=7 mType=0 rnd=8301077\\weights\\best.pt\")\n",
    "\n",
    "# model.task = \"segment\"\n",
    "\n",
    "# results = model.train(data=r\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h5\\UNet 00029 Ep480 images_infer 1\\data_poly.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predict on one image</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(r\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h5\\UNet 00029 Ep480 images_infer 1\\yTrain\\0001.bmp\", show_labels=False, show_boxes=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_bgr = results[0].plot()\n",
    "im_rgb = Image.fromarray(im_bgr[..., ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_rgb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].save_txt(r\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h5\\UNet 00029 Ep480 images_infer 1\\results.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = results[0].tojson()\n",
    "file_path = r\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h5\\UNet 00029 Ep480 images_infer 1\\results1.json\"\n",
    "\n",
    "# Write the JSON string to the JSON file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(json_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predict on multiple images</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 512x512 11 axons, 66 nucleis, 115.0ms\n",
      "1: 512x512 9 axons, 58 nucleis, 115.0ms\n",
      "Speed: 2.0ms preprocess, 115.0ms inference, 659.5ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "results = model([r\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h5\\UNet 00029 Ep480 images_infer 1\\yTrain\\0001.bmp\",r\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h5\\UNet 00029 Ep480 images_infer 1\\yTrain\\0002.bmp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "for i, r in enumerate(results):\n",
    "    # Plot results image\n",
    "    print(i)\n",
    "    im_bgr = r.plot()  # BGR-order numpy array\n",
    "    im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "\n",
    "    # Show results to screen (in supported environments)\n",
    "    im_rgb.show()\n",
    "\n",
    "    # Save results to disk\n",
    "    r.save_txt(rf\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h5\\UNet 00029 Ep480 images_infer 1\\results{i}.txt\")\n",
    "    \n",
    "\n",
    "    # Write the JSON string to the JSON file\n",
    "    file_path = rf\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h5\\UNet 00029 Ep480 images_infer 1\\results{i}.json\"\n",
    "    json_string = results[0].tojson()\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json_file.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = results[0].tojson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your JSON string is stored in the variable json_string\n",
    "\n",
    "# Specify the file path where you want to save the JSON file\n",
    "file_path = r\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h5\\UNet 00029 Ep480 images_infer 1\\results.json\"\n",
    "\n",
    "# Write the JSON string to the JSON file\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json_file.write(json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_bgr = results[1].plot()  # BGR-order numpy array\n",
    "im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image\n",
    "\n",
    "# Show results to screen (in supported environments)\n",
    "im_rgb.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(im_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Trying to export masks</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(results[0].masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "type(results[0].masks.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].masks.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = results[0].masks.xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "plt.pyplot.imshow(results[0].masks.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "transform = T.ToPILImage()\n",
    "img = transform(tensor)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(results[0].masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Predicting on folder of images and exporting data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/10 S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\001597.bmp: 512x512 64 Cells, 635 Droplets, 10.0ms\n",
      "image 2/10 S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\001598.bmp: 512x512 25 Cells, 227 Droplets, 10.0ms\n",
      "image 3/10 S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\001599.bmp: 512x512 16 Cells, 125 Droplets, 9.0ms\n",
      "image 4/10 S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\FIV942P3-5_FIV942P3.A - 4_17_0_0.bmp: 512x512 14 Cells, 88 Droplets, 10.0ms\n",
      "image 5/10 S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\FIV942P3-5_FIV942P3.D - 2_25_0_0.bmp: 512x512 42 Cells, 352 Droplets, 10.0ms\n",
      "image 6/10 S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\FIV942P3-5_FIV942P3.D - 4_7_0_0.bmp: 512x512 5 Cells, 26 Droplets, 11.0ms\n",
      "image 7/10 S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\kath0.bmp: 512x512 91 Cells, 835 Droplets, 9.0ms\n",
      "image 8/10 S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\kath10.bmp: 512x512 26 Cells, 227 Droplets, 9.0ms\n",
      "image 9/10 S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\kath20.bmp: 512x512 77 Cells, 618 Droplets, 9.0ms\n",
      "image 10/10 S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\kath21.bmp: 512x512 38 Cells, 291 Droplets, 13.0ms\n",
      "Speed: 1.1ms preprocess, 10.0ms inference, 38.9ms postprocess per image at shape (1, 3, 512, 512)\n"
     ]
    }
   ],
   "source": [
    "model_path = r\"S:\\Phys\\FIV942 Adipo\\Datasets\\02h9\\YO 512 0320 Snow\\map75=0607616 YOLOv8n-segml idx=5 ep=52 btch=32 rnd=4670342\\weights\\best.pt\"\n",
    "val_data = r\"S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\"\n",
    "# model_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Creed\\01a\\YO 553 0328 MAXI\\map75=0296662 yolov9c  idx=1 ep=8 btch=16 rnd=4717152\\weights\\best.pt\"\n",
    "# val_data = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Creed\\toViz\\nonGABA clusters_F1.ome0.bmp\"\n",
    "\n",
    "adipo_seg = YOLO(model_path)\n",
    "# adipo_seg.task = \"segment\"\n",
    "predictions = adipo_seg.predict(val_data, show=False, max_det = 1000)\n",
    "# with open(r\"s:\\check.json\", \"w\") as text_file:\n",
    "#     text_file.write(res.tojson())\n",
    "\n",
    "#Instead, use dir(res), etc to get the segmentation regions directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting data for a single image\n",
    "img1_data = predictions[0]\n",
    "# img1_mask_coords = img1_data.masks.xy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "if not a:\n",
    "    print('empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(img1_data.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions[0].masks.xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_array = img1_data.plot(labels=False, boxes=True, masks=True)\n",
    "img1 = Image.fromarray(img1_array[..., ::-1])\n",
    "img1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1.save(r\"C:\\Users\\FIVE\\Desktop\\YO 512 0320 Snow predictions\\map75=0605097 YOLOv8n-segml idx=11 ep=60 btch=32 rnd=3869854\\masks.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_data.show(labels=False, boxes=True, masks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_data = predictions[1]\n",
    "img2_array = img2_data.plot(labels=False, boxes=False)\n",
    "img2 = Image.fromarray(img2_array[..., ::-1])\n",
    "img2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2.save(r\"C:\\Users\\FIVE\\Desktop\\YO 512 0320 Snow predictions\\img2_masks.PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon_area(coords):\n",
    "    \"\"\"\n",
    "    Calculate the area of a polygon given its vertices using numpy.\n",
    "    :param coords: A numpy array of shape (n, 2), where n is the number of vertices.\n",
    "    :return: The area of the polygon.\n",
    "    \"\"\"\n",
    "    x = coords[:, 0]\n",
    "    y = coords[:, 1]\n",
    "    i=np.arange(len(x))\n",
    "    # 'shoelace' formula\n",
    "    # return 0.5*np.abs(np.dot(x, np.roll(y, -1)) - np.dot(y, np.roll(x, -1)))\n",
    "    return np.abs(np.sum(x[i-1]*y[i]-x[i]*y[i-1])*0.5)\n",
    "\n",
    "# Example list of numpy arrays as provided\n",
    "polygons = img1_mask_coords\n",
    "\n",
    "# Calculate the area for each polygon and store the results in a new list\n",
    "areas = [polygon_area(polygon) for polygon in polygons]\n",
    "\n",
    "print(\"Areas of the polygons:\", areas)\n",
    "\n",
    "print(\"# of polygons: \", len(areas))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(polygons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example NumPy array and value to search for\n",
    "img1_classes = predictions[0].boxes.cls.numpy()\n",
    "print(img1_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_to_find = 0\n",
    "\n",
    "# Find indices where the value matches\n",
    "class0_indices = np.where(img1_classes == value_to_find)[0]\n",
    "\n",
    "print(\"indices of class 0: \", class0_indices)\n",
    "print(len(class0_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0_indices[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indices where the value matches\n",
    "class1_indices = np.where(img1_classes == 1)[0]\n",
    "\n",
    "print(\"indices of class 1: \", class1_indices)\n",
    "print(len(class1_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_box_coords = img1_data.boxes.xyxy\n",
    "print(len(img1_box_coords))\n",
    "img1_class0_bbox_coords = img1_box_coords[class0_indices]\n",
    "print(len(img1_class0_bbox_coords))\n",
    "img1_class1_bbox_coords = img1_box_coords[class1_indices]\n",
    "print(len(img1_class1_bbox_coords))\n",
    "print(img1_class1_bbox_coords[0])\n",
    "print(img1_class1_bbox_coords.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_box_coords_numpy = img1_box_coords.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(img1_box_coords_numpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize,suppress=True, precision=8)\n",
    "print(img1_class1_bbox_coords.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img1_class0_bbox_coords.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Displaying BBoxes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points provided in xyxy format\n",
    "class1_points = img1_class1_bbox_coords.numpy()\n",
    "\n",
    "# Extracting x and y coordinates for plotting\n",
    "x_values = []\n",
    "y_values = []\n",
    "\n",
    "for point in class1_points:\n",
    "    x_values.extend([point[0], point[2]])\n",
    "    y_values.extend([point[1], point[3]])\n",
    "\n",
    "# Plotting the points\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(x_values, y_values, color='blue')\n",
    "\n",
    "# Adding labels and title for clarity\n",
    "plt.title('Plot of Given Points in XYXY Format')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.grid(True)\n",
    "\n",
    "# plt.gca().invert_xaxis()\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Displaying Droplet Boxes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing boxes with the given points in xyxy format\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Loop through each set of points to draw boxes\n",
    "for i, point in enumerate(class1_points):\n",
    "    # Calculate width and height of the box\n",
    "    width = point[2] - point[0]\n",
    "    height = point[3] - point[1]\n",
    "    \n",
    "    # Create a rectangle patch\n",
    "    rect = plt.Rectangle((point[0], point[1]), width, height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "    \n",
    "    # Add the rectangle patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Add a label to each box\n",
    "    label_x = point[1] + (height / 2)\n",
    "    label_y = point[0] + (width / 2)\n",
    "    ax.text(label_y, label_x, f\"{class1_indices[i]}\", ha='center', va='center', color='blue')\n",
    "\n",
    "# Setting the plot limits to include all boxes comfortably\n",
    "plt.xlim(0, 512)\n",
    "plt.ylim(0, 512)\n",
    "\n",
    "plt.title('Class 1 Boxes')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.grid(True)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class0_points = img1_class0_bbox_coords.numpy()\n",
    "\n",
    "# Extracting x and y coordinates for plotting\n",
    "x_values = []\n",
    "y_values = []\n",
    "\n",
    "for point in class0_points:\n",
    "    x_values.extend([point[0], point[2]])\n",
    "    y_values.extend([point[1], point[3]])\n",
    "\n",
    "# Plotting the points\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(x_values, y_values, color='blue')\n",
    "\n",
    "# Adding labels and title for clarity\n",
    "plt.title('Plot of Given Points in XYXY Format')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.grid(True)\n",
    "\n",
    "# Flip the axes labels and values\n",
    "plt.gca().invert_yaxis()\n",
    "# plt.gca().invert_xaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Displaying Cell Boxes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing boxes with the given points in xyxy format\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "colors = []\n",
    "for color in mcolors.XKCD_COLORS:\n",
    "    colors.append(color)\n",
    "    \n",
    "print(colors)\n",
    "# Loop through each set of points to draw boxes\n",
    "for i, point in enumerate(class0_points):\n",
    "    # Calculate width and height of the box\n",
    "    width = point[2] - point[0]\n",
    "    height = point[3] - point[1]\n",
    "    \n",
    "    # Create a rectangle patch\n",
    "    rect = plt.Rectangle((point[0], point[1]), width, height, linewidth=1, edgecolor=colors[class0_indices[i]], facecolor='none')\n",
    "    \n",
    "    # Add the rectangle patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Add a label to each box\n",
    "    label_x = point[1] + (height / 2)\n",
    "    label_y = point[0] + (width / 2)\n",
    "    ax.text(label_y, label_x, f\"{class0_indices[i]}\", ha='center', va='center', color='blue')\n",
    "\n",
    "# Setting the plot limits to include all boxes comfortably\n",
    "plt.xlim(0, 512)\n",
    "plt.ylim(0, 512)\n",
    "\n",
    "plt.title('Class 0 Boxes')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_parents = []\n",
    "\n",
    "for class1_coord in img1_class1_bbox_coords.numpy():\n",
    "    class1_instance_parents = []\n",
    "    class0_id = 0\n",
    "    print(\"the class1 instance: \", class1_coord)\n",
    "    for class0_coord in img1_class0_bbox_coords.numpy():\n",
    "        print(\"the class0 instance: \", class0_coord)\n",
    "        if class1_coord[0] > class0_coord[2] or class1_coord[2] < class0_coord[0] or class1_coord[1] > class0_coord[3] or class1_coord[3] < class0_coord[1]:\n",
    "            print(\"it wasn't a parent\")\n",
    "            class0_id += 1\n",
    "            print(\"class0_id is now: \", class0_id)\n",
    "            continue\n",
    "        elif (class1_coord[0] > class0_coord[0] and class1_coord[0] < class0_coord[2] and class1_coord[1] > class0_coord[1] and class1_coord[1] < class0_coord[3]) or (class1_coord[2] < class0_coord[2] and class1_coord[2] > class0_coord[0] and class1_coord[3] > class0_coord[1] and class1_coord[3] < class0_coord[3]):\n",
    "            class1_instance_parents.append(class0_indices[class0_id])\n",
    "            print(\"it was an instance, we added \", class0_indices[class0_id])\n",
    "            class0_id += 1\n",
    "            print(\"now class0_id is: \", class0_id)\n",
    "            \n",
    "    class1_parents.append(class1_instance_parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_parents_center_method = []\n",
    "\n",
    "droplet_centers = img1_data.boxes.xywh[class1_indices]\n",
    "cell_centers = img1_data.boxes.xywh[class0_indices]\n",
    "for class1_coord in droplet_centers.numpy():\n",
    "    print(\"the class1 instance: \", class1_coord)\n",
    "    \n",
    "    droplet_x = class1_coord[0]\n",
    "    droplet_y = class1_coord[1]\n",
    "    print(\"droplet x, y coords: \", droplet_x, droplet_y)\n",
    "    min_distance_from_cells = math.inf\n",
    "    parent_cell_index = 0\n",
    "    for i, class0_coord in enumerate(cell_centers.numpy()):\n",
    "        print(\"the class0 instance: \", class0_coord)\n",
    "        \n",
    "        cell_x = class0_coord[0]\n",
    "        cell_y = class0_coord[1]\n",
    "        print(\"cell x, y coords: \", cell_x, cell_y)\n",
    "        point1 = np.array((droplet_x, droplet_y))\n",
    "        point2 = np.array((cell_x, cell_y))\n",
    "        dist = np.linalg.norm(point1 - point2)\n",
    "        print(\"dist from class0 instance: \", dist)\n",
    "        if dist < min_distance_from_cells:\n",
    "            min_distance_from_cells = dist\n",
    "            parent_cell_index = i\n",
    "            \n",
    "    print(\"parent cell index: \", parent_cell_index)        \n",
    "    class1_parents_center_method.append(class0_indices[parent_cell_index])\n",
    "    \n",
    "print(class1_parents_center_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class1_parents_center_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Drawing Droplet Boxes colored by corresponding Cell Boxes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing boxes with the given points in xyxy format\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Loop through each set of points to draw boxes\n",
    "for i, point in enumerate(class1_points):\n",
    "    # Calculate width and height of the box\n",
    "    width = point[2] - point[0]\n",
    "    height = point[3] - point[1]\n",
    "    \n",
    "    # Create a rectangle patch\n",
    "    # print(\"droplet \", i, \" parent \", class1_parents[i])\n",
    "    if not class1_parents[i]:\n",
    "        continue\n",
    "    else:\n",
    "        border_color = colors[class1_parents[i][0]]\n",
    "    rect = plt.Rectangle((point[0], point[1]), width, height, linewidth=1, edgecolor=border_color, facecolor='none')\n",
    "    \n",
    "    # Add the rectangle patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Add a label to each box\n",
    "    # label_x = point[1] + (height / 2)\n",
    "    # label_y = point[0] + (width / 2)\n",
    "    # ax.text(label_y, label_x, f\"{class1_indices[i]}\", ha='center', va='center', color='blue')\n",
    "\n",
    "# Setting the plot limits to include all boxes comfortably\n",
    "plt.xlim(0, 512)\n",
    "plt.ylim(0, 512)\n",
    "\n",
    "plt.title('Class 1 Boxes')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.grid(True)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_box_coords_numpy[202]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class1_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class1_parents) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class1_parents_center_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 17\n",
    "if not class1_parents[a]:\n",
    "    print(\"empty\")\n",
    "else:\n",
    "    print(class1_parents[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(img1_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_classes[44]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Getting pixel intensities (should check)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\\001597.bmp\"\n",
    "image = Image.open(image_path)\n",
    "image_array = np.array(image)\n",
    "\n",
    "pixel_intensity_data = []\n",
    "for mask_outline in range(len(img1_mask_coords)):\n",
    "    vertices = img1_mask_coords[mask_outline]\n",
    "\n",
    "    # Assuming image_array is a 2D numpy array for a grayscale image\n",
    "    # For a color image, you need to decide how to handle the color channels\n",
    "\n",
    "    # Create a mesh grid of coordinate values\n",
    "    xx, yy = np.meshgrid(np.arange(image_array.shape[1]), np.arange(image_array.shape[0]))\n",
    "\n",
    "    # Flatten the grid arrays\n",
    "    x_flat = xx.flatten()\n",
    "    y_flat = yy.flatten()\n",
    "\n",
    "    # Create a list of (x, y) points from the flattened grid\n",
    "    class1_mask_points = np.vstack((x_flat, y_flat)).T\n",
    "\n",
    "    # Create a path object from the vertices\n",
    "    polygon_path = mpltPath.Path(vertices)\n",
    "\n",
    "    # Use the path object to create a mask\n",
    "    inside_polygon = polygon_path.contains_points(class1_mask_points)\n",
    "\n",
    "    # Reshape the mask back to the image shape\n",
    "    mask = inside_polygon.reshape(xx.shape)\n",
    "\n",
    "    # Apply the mask to select pixels within the polygon\n",
    "    # selected_pixels = image_array[mask]\n",
    "\n",
    "    # Sum the intensities of the selected pixels\n",
    "    # sum_of_intensities = np.sum(selected_pixels)\n",
    "\n",
    "    # print(\"Sum of pixel intensities in the polygonal region:\", sum_of_intensities)\n",
    "    # Initialize an array to hold the sum of intensities for each channel\n",
    "    sum_of_intensities_per_channel = np.zeros(image_array.shape[2])\n",
    "\n",
    "    # Iterate over each channel\n",
    "    for i in range(image_array.shape[2]):\n",
    "        # Apply the mask to the current channel and sum the intensities\n",
    "        selected_pixels = image_array[:, :, i][mask]\n",
    "        sum_of_intensities_per_channel[i] = np.sum(selected_pixels)\n",
    "\n",
    "    print(\"Sum of pixel intensities in the polygonal region for each channel:\", sum_of_intensities_per_channel)\n",
    "    pixel_intensity_data.append(sum_of_intensities_per_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pixel_intensity_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drawing boxes with the given points in xyxy format\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Loop through each set of points to draw boxes\n",
    "for i, point in enumerate(class1_points):\n",
    "    # Calculate width and height of the box\n",
    "    width = point[2] - point[0]\n",
    "    height = point[3] - point[1]\n",
    "    \n",
    "    # Create a rectangle patch\n",
    "    # print(\"droplet \", i, \" parent \", class1_parents[i])\n",
    "    # if not class1_parents[i]:\n",
    "    #     continue\n",
    "    # else:\n",
    "    #     border_color = colors[class1_parents[i][0]]\n",
    "    \n",
    "    if max(pixel_intensity_data[class1_indices[i]]) == pixel_intensity_data[class1_indices[i]][0]:\n",
    "        border_color = 'r'\n",
    "    elif max(pixel_intensity_data[class1_indices[i]]) == pixel_intensity_data[class1_indices[i]][1]:\n",
    "        border_color = 'g'\n",
    "    elif max(pixel_intensity_data[class1_indices[i]]) == pixel_intensity_data[class1_indices[i]][2]:\n",
    "        border_color = 'b'\n",
    "    else:\n",
    "        border_color = 'k'\n",
    "    rect = plt.Rectangle((point[0], point[1]), width, height, linewidth=1, edgecolor=border_color, facecolor='none')\n",
    "    \n",
    "    # Add the rectangle patch to the Axes\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    # Add a label to each box\n",
    "    # label_x = point[1] + (height / 2)\n",
    "    # label_y = point[0] + (width / 2)\n",
    "    # ax.text(label_y, label_x, f\"{class1_indices[i]}\", ha='center', va='center', color='blue')\n",
    "\n",
    "# Setting the plot limits to include all boxes comfortably\n",
    "plt.xlim(0, 512)\n",
    "plt.ylim(0, 512)\n",
    "\n",
    "plt.title('Class 1 Boxes')\n",
    "plt.xlabel('X Coordinate')\n",
    "plt.ylabel('Y Coordinate')\n",
    "plt.grid(True)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_intensity_data[class1_indices[0]][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Putting areas of polygons and pixel intensities in spreadsheet (csv)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to add confidence score\n",
    "header = [\"FilePath\", \"PolyID\",\"cls\",\"Vertices\",\"PolyArea\",\"Sum Inten WV0\",\"SumInten WV1\", \"SumInten WV2\",\"BBox x\",\"BBox y\",\"BBox w\",\"BBox h\",\"Conf\", \"Parents\"]\n",
    "data = []\n",
    "\n",
    "class1_counter = 0\n",
    "for i in range(len(img1_classes)):\n",
    "    if img1_mask_coords[i].size == 0:\n",
    "        if img1_classes[i] == 1.0:\n",
    "            class1_counter += 1\n",
    "            print(\"the class of this mask is 1.0, class1 counter is now \", class1_counter)\n",
    "        continue\n",
    "    else:\n",
    "        cls = predictions[0].boxes[i].cls.numpy().item(0)\n",
    "        vertices = polygons[i]\n",
    "        polyArea = areas[i]\n",
    "        bbox_data = predictions[0].boxes[i].xywh.numpy()\n",
    "        conf = predictions[0].boxes.conf.numpy().item(i)\n",
    "        polygon_data = [image_path,i,cls,vertices,polyArea,pixel_intensity_data[i][0],pixel_intensity_data[i][1],pixel_intensity_data[i][2]\n",
    "                        , bbox_data.item(0), bbox_data.item(1), bbox_data.item(2), bbox_data.item(3), conf]\n",
    "        if class1_indices.__contains__(i):\n",
    "            # print(i)\n",
    "            polygon_data.append(class1_parents_center_method[class1_counter])\n",
    "            print(\"class1 index before increment: \", class1_counter)\n",
    "            class1_counter += 1\n",
    "            print(\"class1 index after increment: \", class1_counter)\n",
    "        data.append(polygon_data)\n",
    "\n",
    "filename = 'polygon_image_data_center.csv'\n",
    "with open(filename, 'w', newline=\"\") as file:\n",
    "    csvwriter = csv.writer(file)\n",
    "    csvwriter.writerow(header)\n",
    "    csvwriter.writerows(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Understanding variables (print(), type(), dir(), etc.)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_data.boxes.xywh.numpy()[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data + \"\\\\\" + os.listdir(\"S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, image_data in enumerate(predictions):\n",
    "    print(val_data + \"\\\\\" + os.listdir(val_data)[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.walk(r\"S:\\Phys\\FIV942 Adipo\\Adipo2Viz 512\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_mask_coords[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pixel_intensity_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img1_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_data.boxes.xyxy[class1_indices].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_data.boxes.xywh[class1_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_mask_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for color in mcolors.CSS4_COLORS:\n",
    "    print(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mcolors.XKCD_COLORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(img1_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0].boxes.conf.numpy().item(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0].boxes[1].conf.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(class1_parents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img1_data.boxes.xyxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img1_class0_bbox_coords[0])\n",
    "print(img1_class1_bbox_coords[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions[0].boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res_all[5].boxes[0].orig_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img1_box_coords_numpy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
