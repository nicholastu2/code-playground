{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchvision:  0.17.2\n",
      "CUDA available: True\n"
     ]
    },
    {
     "ename": "TiffFileError",
     "evalue": "not a TIFF file b'BM^}'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\FIVE\\anaconda3\\envs\\torch01\\lib\\site-packages\\tifffile\\tifffile.py:3951\u001b[0m, in \u001b[0;36mTiffFile.__init__\u001b[1;34m(self, file, mode, name, offset, size, omexml, _multifile, _useframes, _parent, **is_flags)\u001b[0m\n\u001b[0;32m   3950\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3951\u001b[0m     byteorder \u001b[38;5;241m=\u001b[39m \u001b[43m{\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mII\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m>\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m<\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m   3952\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[1;31mKeyError\u001b[0m: b'BM'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTiffFileError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m ome_tiff_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPhys\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mFIV925 XSection\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDatasets\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSpinalAtlas\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDodd and Fiederling\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCropped\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2_Inverted_Slides\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mI2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mC3-Slide1-6_Region0007_Channel555 nm,475 nm,395 nm_Seq0051.bmp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m scale_factor \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 17\u001b[0m tif \u001b[38;5;241m=\u001b[39m \u001b[43mtifffile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTiffFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mome_tiff_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m image \u001b[38;5;241m=\u001b[39m tif\u001b[38;5;241m.\u001b[39masarray()\n\u001b[0;32m     20\u001b[0m image_dims \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[1;32mc:\\Users\\FIVE\\anaconda3\\envs\\torch01\\lib\\site-packages\\tifffile\\tifffile.py:3953\u001b[0m, in \u001b[0;36mTiffFile.__init__\u001b[1;34m(self, file, mode, name, offset, size, omexml, _multifile, _useframes, _parent, **is_flags)\u001b[0m\n\u001b[0;32m   3951\u001b[0m     byteorder \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mII\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMM\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEP\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m'\u001b[39m}[header[:\u001b[38;5;241m2\u001b[39m]]\n\u001b[0;32m   3952\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m-> 3953\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TiffFileError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot a TIFF file \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheader\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   3955\u001b[0m version \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(byteorder \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m, header[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m4\u001b[39m])[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   3956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m version \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m43\u001b[39m:\n\u001b[0;32m   3957\u001b[0m     \u001b[38;5;66;03m# BigTiff\u001b[39;00m\n",
      "\u001b[1;31mTiffFileError\u001b[0m: not a TIFF file b'BM^}'"
     ]
    }
   ],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "print(\"torchvision: \", torchvision.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "\n",
    "base_path = r\"R:\\FIVE\\EXP\\FIV925\\Additional Datasets\"\n",
    "dataset = \"Human Colon Cancer\"\n",
    "# ome_tiff_path = f\"{base_path}\\\\{dataset}\\\\Visium_HD_Human_Colon_Cancer_tissue_image.btf\"\n",
    "ome_tiff_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\SpinalAtlas\\Dodd and Fiederling\\Cropped\\2_Inverted_Slides\\I2\\C3-Slide1-6_Region0007_Channel555 nm,475 nm,395 nm_Seq0051.bmp\"\n",
    "scale_factor = 1\n",
    "tif = tifffile.TiffFile(ome_tiff_path)\n",
    "image = tif.asarray()\n",
    "\n",
    "image_dims = image.shape\n",
    "print(\"tif type:\", type(tif))\n",
    "print(\"image type:\", type(image))\n",
    "print(\"shape of image:\", image_dims)\n",
    "print(\"the shape of the image is represented as a:\", type(image_dims))\n",
    "print(\"the first entry in image is:\", image[0][0])\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "mid_y = height // 2\n",
    "mid_x = width // 2\n",
    "top_left_quadrant = image[:mid_y,:mid_x,0]\n",
    "tile_height = (height // 96)\n",
    "tile_width = (width // 96)\n",
    "# somewhere_in_the_middle = image[mid_y:mid_y+tile_height,mid_x:mid_x+tile_width,0]\n",
    "somewhere_in_the_middle = image[mid_y:mid_y+384,mid_x:mid_x+384,0]\n",
    "inverted = 1 - somewhere_in_the_middle\n",
    "plt.imshow(inverted, cmap='gray')\n",
    "plt.axis('off')  # to hide axis labels and ticks \n",
    "\n",
    "# first, what does predicting on this image even look like?\n",
    "# yolo_model_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Brain\\01c\\YO 432 0515 Yeti\\map75=0669758 yolov9c .pt idx=4 ep=8 btch=8 rnd=4229985\\weights\\best.pt\"\n",
    "yolo_model_path = r\"S:\\Phys\\FIV925XSection\\Datasets\\AllenBA\\02b\\YO 512 0515 MAXI\\map75=0804727 YOLOv8n-seg .yaml idx=17 ep=57 btch=32 rnd=8367787\\weights\\best.pt\"\n",
    "arr_as_img = Image.fromarray(inverted, 'L')\n",
    "model = YOLO(yolo_model_path)\n",
    "prediction = model.predict(image)\n",
    "im_array = prediction[0].plot(labels=False)\n",
    "\n",
    "plt.imshow(im_array)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
    "# im.show()  # show image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "\n",
    "print(\"torchvision: \", torchvision.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "\n",
    "base_path = r\"R:\\FIVE\\EXP\\FIV925\\Additional Datasets\"\n",
    "dataset = \"Human Colon Cancer\"\n",
    "ome_tiff_path = f\"{base_path}\\\\{dataset}\\\\Visium_HD_Human_Colon_Cancer_tissue_image.btf\"\n",
    "scale_factor = 1\n",
    "tif = tifffile.TiffFile(ome_tiff_path)\n",
    "image = tif.asarray()\n",
    "\n",
    "image_dims = image.shape\n",
    "print(\"tif type:\", type(tif))\n",
    "print(\"image type:\", type(image))\n",
    "print(\"shape of image:\", image_dims)\n",
    "print(\"the shape of the image is represented as a:\", type(image_dims))\n",
    "print(\"the first entry in image is:\", image[0][0])\n",
    "\n",
    "height, width = image.shape[:2]\n",
    "mid_y = height // 2\n",
    "mid_x = width // 2\n",
    "top_left_quadrant = image[:mid_y, :mid_x, 0]\n",
    "tile_height = height // 96\n",
    "tile_width = width // 96\n",
    "somewhere_in_the_middle = image[mid_y:mid_y + tile_height, mid_x:mid_x + tile_width, 0]\n",
    "inverted = 1 - somewhere_in_the_middle\n",
    "\n",
    "# Create a figure with 2 subplots\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Display the first image\n",
    "axs[0].imshow(inverted, cmap='gray')\n",
    "axs[0].axis('off')  # to hide axis labels and ticks\n",
    "\n",
    "# first, what does predicting on this image even look like?\n",
    "yolo_model_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Brain\\01c\\YO 432 0515 Yeti\\map75=0669758 yolov9c .pt idx=4 ep=8 btch=8 rnd=4229985\\weights\\best.pt\"\n",
    "arr_as_img = Image.fromarray(inverted, 'L')\n",
    "model = YOLO(yolo_model_path)\n",
    "prediction = model.predict(arr_as_img, conf=0.5)\n",
    "im_array = prediction[0].plot(labels=False)\n",
    "\n",
    "# Display the second image\n",
    "axs[1].imshow(im_array)\n",
    "axs[1].axis('off')\n",
    "\n",
    "# Show the figure\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT Code voronoi boundaries (whole image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import pandas as pd\n",
    "import torch, torchvision\n",
    "from scipy.spatial import Voronoi, voronoi_plot_2d\n",
    "\n",
    "print(\"torchvision: \", torchvision.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "\n",
    "base_path = r\"R:\\FIVE\\EXP\\FIV925\\Additional Datasets\"\n",
    "\n",
    "dataset = \"Human Colon Cancer\"\n",
    "ome_tiff_path = f\"{base_path}\\\\{dataset}\\\\Visium_HD_Human_Colon_Cancer_tissue_image.btf\"\n",
    "\n",
    "scale_factor = 1\n",
    "\n",
    "tif = tifffile.TiffFile(ome_tiff_path)\n",
    "\n",
    "image = tif.asarray()\n",
    "tile_size = 384\n",
    "image_height, image_width = image.shape[:2]\n",
    "yolo_model_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Brain\\01c\\YO 432 0515 Yeti\\map75=0669758 yolov9c .pt idx=4 ep=8 btch=8 rnd=4229985\\weights\\best.pt\"\n",
    "model = YOLO(yolo_model_path)\n",
    "df = pd.DataFrame()\n",
    "image_single_channel = image[:,:,0]\n",
    "\n",
    "list_of_centers = []\n",
    "\n",
    "# for each tile in the image ...\n",
    "# I wanna predict on the tile, and also draw voronoi boxes over it?\n",
    "#   Ohh, so I need to predict on the image to find the centers of the cells, then use voronoi to draw the boundaries over the cells\n",
    "tile_height = tile_size\n",
    "tile_width = tile_size\n",
    "\n",
    "for i in range(0, image_height, tile_height): # section_miny, section_maxy\n",
    "    for j in range(0, image_width, tile_width): # section_minx, section_maxx\n",
    "        tile = image_single_channel[i:i+tile_height, j:j+tile_width]\n",
    "        if tile.shape[0] == 0 or tile.shape[1] == 0:\n",
    "            continue  # Skip tiles that have no width or height\n",
    "        \n",
    "        tile_as_img = Image.fromarray(tile, 'L')\n",
    "        predictions = model.predict(tile_as_img, show=False, max_det=3000)\n",
    "        \n",
    "        result = predictions[0]\n",
    "        \n",
    "        # ok, so I can just make a list of the centers of the predictions and have the voronoi algorithm make the segmentations\n",
    "        boxes_tensor = result.boxes.xywh\n",
    "        boxes_array = boxes_tensor.cpu().numpy()\n",
    "        centers = boxes_array[:, :2]\n",
    "        \n",
    "        # need to flip i and j here because the list of boxes are of form xy instead of row,col\n",
    "        to_add = np.array([j,i])\n",
    "        \n",
    "        centers_scaled = centers + to_add\n",
    "        \n",
    "        if centers.size != 0:\n",
    "            list_of_centers.append(centers_scaled)\n",
    "\n",
    "# Flatten the list of centers\n",
    "all_centers = np.vstack(list_of_centers)\n",
    "\n",
    "# Create a Voronoi diagram from the centers\n",
    "vor = Voronoi(all_centers)\n",
    "\n",
    "# Plot the image\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(image_single_channel, cmap='gray')\n",
    "ax.axis('off')\n",
    "\n",
    "# Plot Voronoi diagram\n",
    "voronoi_plot_2d(vor, ax=ax, show_vertices=False, line_colors='red', line_width=1)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
