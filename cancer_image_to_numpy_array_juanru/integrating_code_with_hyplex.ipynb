{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyplex code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "from ultralytics import YOLO\n",
    "import io\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpltPath\n",
    "from scipy.spatial import Voronoi\n",
    "import colorsys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_by_id(point_region_id, total_ids):\n",
    "    hue = point_region_id / total_ids # Scale the hue by the number of unique IDs, wrapping around the hue circle\n",
    "    saturation = 0.9; value = 0.9  # Keep saturation and value high for bright colors\n",
    "    rgb = colorsys.hsv_to_rgb(hue, saturation, value)\n",
    "    return tuple(int(c * 255) for c in rgb) # Convert to 0-255 scale for RGB colors in PIL\n",
    "\n",
    "def get_vor_boundaries(boxes, ImgIfDesired = None):\n",
    "    points= []; vor_verts = {}\n",
    "    for idx in range(len(boxes)): points.append((boxes[idx][0], boxes[idx][1]))\n",
    "    vor_verts_list = []\n",
    "    try:\n",
    "        vor = Voronoi(points)\n",
    "    except:\n",
    "        return vor_verts_list\n",
    "    for point_region_id, region_id in enumerate(vor.point_region): #this is needed to preserve the order\n",
    "        if (-1 not in vor.regions[region_id]):\n",
    "            region_vertices = vor.vertices[vor.regions[region_id]]\n",
    "            vor_verts[point_region_id] = region_vertices.tolist()\n",
    "\n",
    "    default_triangle_height = 2; default_triangle_base_length = 4\n",
    "    for idx, point in enumerate(points):\n",
    "        if idx in vor_verts:  # Voronoi region exists\n",
    "            vor_verts_list.append(vor_verts[idx])\n",
    "        else:  # Create default triangle for missing regions\n",
    "            bl_vertex = (point[0] - default_triangle_base_length / 2, point[1])\n",
    "            br_vertex = (point[0] + default_triangle_base_length / 2, point[1])\n",
    "            top_vertex = (point[0], point[1] + default_triangle_height)  \n",
    "            vor_verts_list.append([bl_vertex, br_vertex, top_vertex])\n",
    "    \n",
    "    if (ImgIfDesired):\n",
    "        drawV = ImageDraw.Draw(ImgIfDesired)\n",
    "        r = 2  # radius of the points\n",
    "        for point_region_id, point in enumerate(points):\n",
    "            outline_color = get_color_by_id(point_region_id, len(points))\n",
    "            left_up_point = (point[0] - r, point[1] - r)\n",
    "            right_down_point = (point[0] + r, point[1] + r)\n",
    "            if vor_verts.get(point_region_id) and len(vor_verts[point_region_id]) > 0:\n",
    "                polygon_vertices_tuples = [tuple(vertex) for vertex in vor_verts[point_region_id]]\n",
    "                drawV.polygon(polygon_vertices_tuples, width=3, outline=outline_color)\n",
    "            drawV.ellipse([left_up_point, right_down_point], fill=outline_color)\n",
    "\n",
    "        display(imgV)\n",
    "    return vor_verts_list\n",
    "\n",
    "def find_mask_intensities(img_data, image_array, file_name, fraction_complete = 0,shift_x = 0, shift_y = 0, full_width = -1, full_height = -1, include_headers = True, meta_name = \"NA\", tile_name = \"NA\", max_bb_area = 99999, macro_model_list = []):\n",
    "    sto = io.StringIO()\n",
    "    sth = ''; d = '\\t'\n",
    "\n",
    "    def bstr_h(sth1):\n",
    "        nonlocal sth\n",
    "        sth += sth1\n",
    "\n",
    "    def bstr_m(st1):\n",
    "        sto.write(st1)\n",
    "\n",
    "    def bstr_m_start():\n",
    "        nonlocal sth, sto\n",
    "        st = sth + '\\r' + sto.getvalue()\n",
    "        sto.close()\n",
    "        sto = io.StringIO()\n",
    "        sto.write(st)\n",
    "\n",
    "    def get_mask(vertices):\n",
    "        polygon_path = mpltPath.Path(vertices) # Create a path object from the vertices\n",
    "        inside_polygon = polygon_path.contains_points(class_points)\n",
    "        mask = inside_polygon.reshape(xx.shape) # Reshape the mask back to the image shape\n",
    "        return mask\n",
    "\n",
    "    width =image_array.shape[1]; height = image_array.shape[0]; channels = image_array.shape[2]\n",
    "    boxes = img_data.boxes.cpu()\n",
    "    img_box_centers = boxes.xywh \n",
    "    img_mask_coords = None if img_data.masks is None else img_data.masks.xy\n",
    "    img_vor_coords = get_vor_boundaries(img_box_centers)\n",
    "\n",
    "    # Now we want to see if the mask contains anything in teh macro model\n",
    "\n",
    "    first = include_headers; masks = {}\n",
    "    print(f\"{fraction_complete:.1%}\",\" > width =\",width,\"height =\",height,\"chs =\",channels,\"boxes =\",len(img_box_centers),\"vor =\",len(img_vor_coords))\n",
    "    xx, yy = np.meshgrid(np.arange(width),np.arange(height)) # Create a mesh grid of coordinate values\n",
    "    x_flat = xx.flatten(); y_flat = yy.flatten()\n",
    "    class_points = np.vstack((x_flat, y_flat)).T # Create a list of (x, y) points from the flattened grid\n",
    "    for idx in range(len(img_box_centers)):\n",
    "        if (idx % 500 == 499): print(\"Measuring Intensities\",idx)\n",
    "        bbox_xywh = img_box_centers[idx]\n",
    "        bbox_corners = [[bbox_xywh[0] - bbox_xywh[2], bbox_xywh[1] + bbox_xywh[3]],[bbox_xywh[0] + bbox_xywh[2], bbox_xywh[1] + bbox_xywh[3]] ,[bbox_xywh[0] + bbox_xywh[2], bbox_xywh[1] - bbox_xywh[3]], [bbox_xywh[0] - bbox_xywh[2], bbox_xywh[1] - bbox_xywh[3]]]\n",
    "        vor_corners = img_vor_coords[idx] if img_vor_coords else None\n",
    "        polys = { \"box\": bbox_corners, \"poly\": img_mask_coords,  **({\"vor\": vor_corners} if vor_corners else {}) }\n",
    "        masks = {key: get_mask(value) for key, value in polys.items() if value}\n",
    "\n",
    "        cx = bbox_xywh[0].item() + shift_x; cy = bbox_xywh[1].item() + shift_y\n",
    "        if (first): bstr_h('FileName' + d + 'MetaName' + d + 'TileName' + d + 'ObjectID' + d + 'Class'                         + d + 'Confidence'                + d + 'cx'    + d + 'cy'    + d)\n",
    "        bstr_m(             file_name + d + meta_name  + d +  tile_name + d + str(idx)   + d + str(int(boxes[idx].cls.item())) + d + str(boxes[idx].conf.item()) + d + str(cx) + d + str(cy) + d)  #I just added the +d at the end on 6/18/2024\n",
    "\n",
    "        for ma in macro_model_list:\n",
    "            ry = int(ma.dim_x * cx / full_width)\n",
    "            rx = int(ma.dim_y * cy / full_height)\n",
    "            mac_cls, mac_conf = ma.instance_mask[rx,ry,0], ma.instance_mask[rx,ry,1]\n",
    "            #print(cx,full_width, ma.dim_x, rx, mac_cls, mac_conf)\n",
    "            if (first): bstr_h(\"Macro Cls \" + ma.name[:8] + d + \"Macro Conf \" + ma.name[:8] + d)\n",
    "            bstr_m(     str(int(mac_cls))             + d + str(mac_conf)           + d)\n",
    "\n",
    "        # Look at each mask for each channel\n",
    "        for c in range(channels):\n",
    "            cs = str(c)\n",
    "            for key in masks:\n",
    "                selected_pixels = image_array[:, :, c][masks[key]]\n",
    "                area = len(selected_pixels)\n",
    "                #TODO: Add in Major Minor (maj, min) = major_minor_axis_lengths(?,?) # Probably only for the polygon masks\n",
    "                if (first and c==0): bstr_h(key + ' AreaP' + d)\n",
    "                if (c==0): bstr_m(               str(area) + d)\n",
    "\n",
    "                sum = np.sum(selected_pixels)\n",
    "                avg = np.average(selected_pixels)\n",
    "                std = np.std(selected_pixels)\n",
    "                if (first): bstr_h(key + ' Total Intensity wv' + cs + d + key + ' Avg Intensity wv' + cs + d + key + ' Std Intensity wv' + cs + d)\n",
    "                bstr_m(                    str(sum)                 + d + str(avg)                       + d + str(std)                       + d)\n",
    "\n",
    "        if (first): bstr_m_start(); first = False\n",
    "        bstr_m('\\r')\n",
    "    return sto.getvalue()\n",
    "\n",
    "def Predict_OnPartsOfImage(model_simpleType, original_image_name, full_image_arr_predict, full_image_arr_measure = None, save_path = None, save_imgs = None, overlap_amount = 0, fill_edges = False, include_headers = True, meta_name = \"NA\", testMode = False, maxdets = 6666, macro_model_list = []):\n",
    "    new_w = model_simpleType.dim_x; new_h = model_simpleType.dim_y\n",
    "    \n",
    "    def get_piece(t_arr, x, y):\n",
    "        piece = t_arr[y:min(y + new_h, t_arr.shape[0]), x:min(x + new_w, t_arr.shape[1])] # Calculate the dimensions of the piece\n",
    "        if fill_edges: # Create a new array filled with zeros (black) of the desired final size\n",
    "            filled_piece = np.zeros((new_h, new_w), dtype=t_arr.dtype)\n",
    "            filled_piece[:piece.shape[0], :piece.shape[1]] = piece\n",
    "            piece = filled_piece\n",
    "        return piece\n",
    "            \n",
    "    t_arr = full_image_arr_predict\n",
    "    first = include_headers\n",
    "    st = io.StringIO()\n",
    "    w, h = t_arr.shape[1], t_arr.shape[0]\n",
    "    tPath = os.path.join(save_imgs,cPredImgFldr); os.makedirs(tPath, exist_ok=True)\n",
    "    total_tiles = (h+1)/(new_h - overlap_amount) * (w+1)/(new_w - overlap_amount); tile_counter = 0.0\n",
    "    for y in range(0, h, new_h - overlap_amount):\n",
    "        for x in range(0, w, new_w - overlap_amount):\n",
    "            tile_counter += 1\n",
    "            piece_pred = get_piece(t_arr, x, y)\n",
    "            piece_meas = get_piece(full_image_arr_measure, x, y) if (full_image_arr_measure is not None) else piece_pred\n",
    "            tilename = str(x) + \",\" + str(y); print(\"Region:\",tilename)\n",
    "            predictions = model_simpleType.model.predict(piece_pred, show=False, max_det=maxdets, conf=model_simpleType.min_conf, half=True) \n",
    "            if save_imgs is not None: \n",
    "                img_array=predictions[0].plot(labels=False, boxes=True, masks=True); Image.fromarray(img_array[..., ::-1]).save(os.path.join(tPath, tilename + \".jpg\"))\n",
    "            st.write(find_mask_intensities(predictions[0], piece_meas, original_image_name, tile_counter/total_tiles, x, y, w, h, first, meta_name, tilename, model_simpleType.max_area, macro_model_list))\n",
    "            if (testMode and not first): break # This will give us exactly two regions\n",
    "            first = False\n",
    "        if (testMode and not first): break\n",
    "\n",
    "    strRet = st.getvalue()\n",
    "    if (save_path is not None):\n",
    "        with open(save_path, 'a') as file: file.write(strRet)\n",
    "        st.close()\n",
    "    print(\"Done with File\")\n",
    "    return strRet\n",
    "\n",
    "cPredImgFldr = \"_PredImgs\"\n",
    "def create_multichannel_array(folder_path, down_x = 1, down_y = 1):\n",
    "    image_arrays = []\n",
    "    image_names = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        if (os.path.basename(root) == cPredImgFldr): continue\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png', '.jpg', '.jpeg','.bmp','.tif')):\n",
    "                print(\"loading \", file)\n",
    "                file_path = os.path.join(root, file)\n",
    "                #t_img = Image.open(file_path).convert('L');  # Convert to grayscale if not already # Old Way\n",
    "                \n",
    "                t_img = Image.open(file_path); \n",
    "                width, height = t_img.size  \n",
    "                new_width = int(width * down_x); new_height = int(height * down_y)\n",
    "                t_img = t_img.resize((new_width, new_height), Image.Resampling.BILINEAR) # Resize the image\n",
    "\n",
    "                t_arr = np.array(t_img) \n",
    "                #max_intensity = np.max(t_arr); \n",
    "                #img_8bit = (255.0 * img_array / max_intensity).astype('uint8')\n",
    "                #img = Image.fromarray(img_8bit).convert('RGB'); width, height = img.size\n",
    "                \n",
    "                if t_arr.ndim == 2:  # Ensure the image is grayscale\n",
    "                    image_arrays.append(t_arr)\n",
    "                    image_names.append(file)\n",
    "    \n",
    "    if not image_arrays:\n",
    "        return None  # Or raise an exception if you prefer\n",
    "\n",
    "    # Stack the arrays along a new axis to create a multi-channel array\n",
    "    multi_channel_array = np.stack(image_arrays, axis=-1)\n",
    "    return multi_channel_array, image_names\n",
    "\n",
    "def create_instance_mask(image_width, image_height, yolo_results_data, show_test_mask = False):\n",
    "    \"\"\"\n",
    "    Create a mask where each pixel value represents the instance class.\n",
    "\n",
    "    :param image_shape: A tuple (height, width) representing the image shape.\n",
    "    :param masks: The masks from the YOLOv8 results.\n",
    "    :param classes: The classes of each instance.\n",
    "    :return: A mask array where each pixel value represents the instance class. First channel is class, 2nd is confidence, 3rd is 0\n",
    "    \"\"\"\n",
    "    boxes = yolo_results_data.boxes.cpu()\n",
    "    masks = yolo_results_data.masks.cpu()\n",
    "    classes_conf = [(boxes[idx].cls.item(),boxes[idx].conf.item()) for idx in range(len(boxes))]\n",
    "    instance_mask = np.zeros((image_width, image_height, 3), dtype=float) # dtype=np.int32)\n",
    "\n",
    "    for idx in range(len(boxes)):\n",
    "        poly_cors = masks[idx].xy[0]\n",
    "        path = mpltPath.Path(poly_cors)\n",
    "        y, x = np.mgrid[:image_width, :image_height]\n",
    "        points = np.vstack((x.ravel(), y.ravel())).T\n",
    "        mask = path.contains_points(points)\n",
    "        mask = mask.reshape((image_width, image_height))\n",
    "        #instance_mask[mask] = classes_conf[idx] \n",
    "        instance_mask[mask, 0] = classes_conf[idx][0]\n",
    "        instance_mask[mask, 1] = classes_conf[idx][1]\n",
    "    if (show_test_mask):\n",
    "        plt.figure()\n",
    "        plt.imshow(instance_mask, cmap='gray')\n",
    "        plt.title('Mask')\n",
    "        plt.show()\n",
    "    return instance_mask\n",
    "\n",
    "def find_first_file(m_folder, m_contains):\n",
    "    for root, dirs, files in os.walk(m_folder):\n",
    "        for file in files:\n",
    "            if m_contains in file:\n",
    "                return os.path.join(root, file)\n",
    "    return None\n",
    "\n",
    "def work_on_folder(model_simpleType, macro_model_list, SubFolder, PredContains, down_x = 1, down_y = 1, testMode = False, IncludeHeaders = True, save_path = None, maxdet = 10000, overlap = 0):\n",
    "    file_pred = find_first_file(SubFolder, PredContains)\n",
    "    \n",
    "    if file_pred is None:\n",
    "        return None\n",
    "\n",
    "    # Prep the large image for micro predictions\n",
    "    img = Image.open(file_pred); img_array = np.array(img); # This code can handle 8 and 16-bit TIFFs . . not sure about RGB\n",
    "    # this line is giving an error, fil_pred is type None for some reason, why is this?\n",
    "    #   well, file_pred is defined on line 232\n",
    "    #   bruh, find_first_file returns None for some reason\n",
    "    #   oh, only if m_contains isn't in m_folder\n",
    "    #   so, I'm getting an error because the file I'm looking for isn't in that folder\n",
    "    #       let's check what file and folder I was looking at\n",
    "    # So the folder I'm looking at has multiple subfolders\n",
    "    #   so it looks like find_first_file only looks at the set of files in a folder?\n",
    "    #   shouldn't it be that find_first_file looks in all the subdirectories?\n",
    "    \n",
    "    max_intensity = np.max(img_array); img_8bit = (255.0 * img_array / max_intensity).astype('uint8')\n",
    "    img = Image.fromarray(img_8bit).convert('RGB'); width, height = img.size\n",
    "    if (down_x < 1 or down_y < 1):\n",
    "        new_width = int(width * down_x); new_height = int(height * down_y)\n",
    "        img = img.resize((new_width, new_height), Image.Resampling.BILINEAR) # Resize the image before micro model\n",
    "        print(\"  Resized image from\", width, height, \" to\", new_width, new_height)\n",
    "    pred_arr_m0 = np.array(img) # Convert to array\n",
    "    print(\" Loaded data from image\", img.width, \"x\", img.height,\" m\", img.mode, \" Orig Max\",max_intensity, \" min\", np.min(pred_arr_m0), \" max\", str(np.max(pred_arr_m0)))\n",
    "    \n",
    "    # Prep for Macro predictions (if there are any requested)\n",
    "    if macro_model_list: #checks both not none and has list elements\n",
    "        resize_dict = {}\n",
    "        for ma in macro_model_list:\n",
    "            key = (ma.dim_x, ma.dim_y)\n",
    "            res_img = resize_dict.get(key)\n",
    "            if res_img is None: \n",
    "                p_img = img.resize(key, Image.Resampling.BILINEAR)\n",
    "                res_img  = np.array(p_img); resize_dict[key] = res_img\n",
    "            print(\"  Running Macro Model\", ma.name, \" on resized image\")\n",
    "            ma.res = ma.model.predict(res_img)\n",
    "            ma.instance_mask = create_instance_mask(ma.dim_x, ma.dim_y, ma.res[0])\n",
    "            img_array=ma.res[0].plot(labels=False, boxes=True, masks=True)\n",
    "            tPath = os.path.join(SubFolder, cPredImgFldr); os.makedirs(tPath, exist_ok=True)\n",
    "            Image.fromarray(res_img).save(os.path.join(tPath, \"orig1.jpg\"))\n",
    "            Image.fromarray(img_array[..., ::-1]).save(os.path.join(tPath, \"macro1.jpg\"))\n",
    "            img.save(os.path.join(tPath, \"orig1.jpg\"))\n",
    "\n",
    "    meas_arr_m0, names = create_multichannel_array(SubFolder, down_x, down_y)\n",
    "    st = Predict_OnPartsOfImage(model_simpleType, file_pred, pred_arr_m0, meas_arr_m0, None, SubFolder, overlap, False, IncludeHeaders, SubFolder, testMode, maxdet, macro_model_list) #st = Predict_OnPartsOfImage(m0.model, file_pred, pred_arr_m0, meas_arr_m0, None, dim_x, dim_y, 0, False, IncludeHeaders, SubFolder, testMode, maxdet, m0.min_conf, m0.max_area) # Old Style\n",
    "    if (save_path is not None): \n",
    "        with open(save_path, 'a') as file: file.write(st)\n",
    "    print(\"Done with Files\")\n",
    "    return st, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creed\n",
    "\n",
    "model_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Creed\\01a\\YO 553 0328 MAXI\\map75=0296662 yolov9c  idx=1 ep=8 btch=16 rnd=4717152\\weights\\best.pt\"\n",
    "m_folder = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Creed\\20240406\"\n",
    "m_contains = \"T0_DAPI\"\n",
    "res_append = \"2\"\n",
    "dim_x, dim_y = 553, 553\n",
    "down_x, down_y = 1, 1\n",
    "max_area = 1000\n",
    "min_conf = 0.2\n",
    "testMode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dougherty Allen\n",
    "\n",
    "model_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Brain\\01a\\YO 384 0326 MAXI\\map75=0650739 yolov9c  idx=12 ep=11 btch=8 rnd=6376250\\weights\\best.pt\"\n",
    "m_folder = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Brain\\Dougherty\\Orig\" # Needs to be in one more subfolder after that\n",
    "m_contains = \"DAPI\"\n",
    "res_append = \"2\"\n",
    "dim_x, dim_y = 384, 384\n",
    "down_x, down_y = 0.5, 0.5\n",
    "max_area = 30000\n",
    "min_conf = 0.5\n",
    "testMode = False\n",
    "\n",
    "#Implement intensity threshold to show preview images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spinal Cord 2 Scales\n",
    "\n",
    "m_folder = r\"S:\\Phys\\FIV925 XSection\\Datasets\\SpinalAtlas\\Dodd and Fiederling\\Cropped\\2\\R2\" # Needs to be in one more subfolder after that\n",
    "m_contains = \"C3\" #This is what to focus the segmentation (micro) model on, usually DAPI\n",
    "res_append = \"4\"  #This just changes the name of the save folder\n",
    "testMode = False\n",
    "m0_down_x, m0_down_y = 1, 1   # Specifies specific ratio of downsampling before starting\n",
    "\n",
    "# We need a metadata system like we have for the other models, that way we can load all of the parameters about using the model without having to specify them\n",
    "#if 'm2' in locals(): m2.model = YOLO(m2.model_path), if hasattr(m1, 'model'): # This checks if a member is present (m1.model for example)\n",
    "\n",
    "# - - - - Micro Level\n",
    "m0 = types.SimpleNamespace()\n",
    "m0.model_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Brain\\01c\\YO 432 0515 Yeti\\map75=0669758 yolov9c .pt idx=4 ep=8 btch=8 rnd=4229985\\weights\\last.pt\" \n",
    "m0.dim_x, m0.dim_y = 448, 448  # Model input dimensions (will tile this)\n",
    "m0.max_area = 30000\n",
    "m0.min_conf = 0.32\n",
    "\n",
    "# - - - - - Macro Levels\n",
    "ms = []; ms.append(types.SimpleNamespace())\n",
    "ms[0].model_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\AllenBA\\02b\\YO 512 0515 MAXI\\map75=0804727 YOLOv8n-seg .yaml idx=17 ep=57 btch=32 rnd=8367787\\weights\\best.pt\"\n",
    "ms[0].dim_x, ms[0].dim_y = 512, 512  # Model input dimensions (will tile this)\n",
    "ms[0].max_area = 30000000\n",
    "ms[0].min_conf = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_PredImgs ---------------------------------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\FIVE\\anaconda3\\envs\\torch01\\lib\\site-packages\\PIL\\Image.py:3251\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3251\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m subfolder_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(m_folder, subfolder)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# subfolder_path is SubFolder\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# and m_contains is PredContains\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m st, names \u001b[38;5;241m=\u001b[39m \u001b[43mwork_on_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubfolder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_contains\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm0_down_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm0_down_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestMode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFirst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m stio\u001b[38;5;241m.\u001b[39mwrite(st); namedict[subfolder] \u001b[38;5;241m=\u001b[39m names; First \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (testMode): \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 235\u001b[0m, in \u001b[0;36mwork_on_folder\u001b[1;34m(model_simpleType, macro_model_list, SubFolder, PredContains, down_x, down_y, testMode, IncludeHeaders, save_path, maxdet, overlap)\u001b[0m\n\u001b[0;32m    232\u001b[0m file_pred \u001b[38;5;241m=\u001b[39m find_first_file(SubFolder, PredContains)\n\u001b[0;32m    234\u001b[0m \u001b[38;5;66;03m# Prep the large image for micro predictions\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_pred\u001b[49m\u001b[43m)\u001b[49m; img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img); \u001b[38;5;66;03m# This code can handle 8 and 16-bit TIFFs . . not sure about RGB\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# this line is giving an error, fil_pred is type None for some reason, why is this?\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m#   well, file_pred is defined on line 232\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m#   bruh, find_first_file returns None for some reason\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m#   oh, only if m_contains isn't in m_folder\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m#   so, I'm getting an error because the file I'm looking for isn't in that folder\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m#       let's check what file and folder I was looking at\u001b[39;00m\n\u001b[0;32m    243\u001b[0m max_intensity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(img_array); img_8bit \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m255.0\u001b[39m \u001b[38;5;241m*\u001b[39m img_array \u001b[38;5;241m/\u001b[39m max_intensity)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\FIVE\\anaconda3\\envs\\torch01\\lib\\site-packages\\PIL\\Image.py:3253\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3251\u001b[0m     fp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   3252\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n\u001b[1;32m-> 3253\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m())\n\u001b[0;32m   3254\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3256\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "# Load models\n",
    "m0.model = YOLO(m0.model_path)\n",
    "for m in ms: \n",
    "    m.model = YOLO(m.model_path); m.name = os.path.basename(os.path.dirname(os.path.dirname(m.model_path)))\n",
    "\n",
    "Image.MAX_IMAGE_PIXELS = None #Turn off the limit\n",
    "first_level_subfolders = next(os.walk(m_folder))[1]  # Get first level of folders only\n",
    "First = True; stio = io.StringIO(); namedict = {}\n",
    "for subfolder in first_level_subfolders:\n",
    "    print(subfolder,\"---------------------------------\")\n",
    "    subfolder_path = os.path.join(m_folder, subfolder)\n",
    "    \n",
    "    # subfolder_path is SubFolder\n",
    "    # and m_contains is PredContains\n",
    "    st, names = work_on_folder(m0, ms, subfolder_path, m_contains, m0_down_x, m0_down_y, testMode, First)\n",
    "    \n",
    "    stio.write(st); namedict[subfolder] = names; First = False\n",
    "    if (testMode): break\n",
    "\n",
    "# Save out the main data\n",
    "Prefix = f\"Res00{res_append}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "save_path = os.path.join(m_folder, Prefix + \".txt\"); strRet = stio.getvalue(); stio.close()\n",
    "with open(save_path, 'a') as file: file.write(strRet)\n",
    "\n",
    "# Now save out the name information\n",
    "save_path = os.path.join(m_folder, Prefix + \"_Names.txt\")\n",
    "rows = [f\"{subfolder}\\t{idx}\\t{name}\" for subfolder, names in namedict.items() for idx, name in enumerate(names)]\n",
    "with open(save_path, 'w') as txtfile:\n",
    "    txtfile.write(\"Subfolder\\tIndex\\tName\\n\"); txtfile.write(\"\\n\".join(rows))\n",
    "\n",
    "print(\"Done with Folder\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
