{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the brain_annotations.txt file\n",
    "with open(r\"S:\\Phys\\FIV925 XSection\\Datasets\\SpinalAtlas\\Dodd and Fiederling\\Cropped\\8_Inverted_Slides\\I8\\spinal_cord_annotations.txt\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Function to normalize the points with 17 decimal places\n",
    "def normalize_point(x, y, x_max=2982, y_max=2982):\n",
    "    return f\"{x / x_max:.17f} {y / y_max:.17f}\"\n",
    "\n",
    "# Initialize a dictionary to hold the object data\n",
    "objects = {}\n",
    "\n",
    "# Process the data\n",
    "for box in data['boxes']:\n",
    "    label = box['label']\n",
    "    points = box['points']\n",
    "    if label not in objects:\n",
    "        objects[label] = []\n",
    "    else:\n",
    "        label = label +\"n\"\n",
    "        objects[label] = []\n",
    "    objects[label].extend([normalize_point(point[0], point[1]) for point in points])\n",
    "\n",
    "# Create the normalized formatted string\n",
    "normalized_output = \"\"\n",
    "for label in sorted(objects.keys()):\n",
    "    normalized_output += f\"{label} \" + \" \".join(objects[label]) + \"\\n\"\n",
    "\n",
    "# Write the normalized output to a new file\n",
    "output_file_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\SpinalAtlas\\Dodd and Fiederling\\Cropped\\8_Inverted_Slides\\I8\\normalized_spinal_cord_annotations.txt\"\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    output_file.write(normalized_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Nissl annotations to yolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Slice 875.txt file with the appropriate encoding\n",
    "file_path = r\"R:\\FIVE\\EXP\\FIV925\\SC_Mendeley\\Results\\Val on nissl\\Slice 875.txt\"\n",
    "data = pd.read_csv(file_path, delimiter='\\t', encoding='utf-16')\n",
    "\n",
    "# Normalize the X and Y coordinates\n",
    "data['X'] = data['X'] / 322\n",
    "data['Y'] = data['Y'] / 253\n",
    "\n",
    "# Create a dictionary to store the points for each Region ID\n",
    "normalized_annotations = {}\n",
    "for _, row in data.iterrows():\n",
    "    region_id = int(row['Region ID'])\n",
    "    x, y = row['X'], row['Y']\n",
    "    if region_id not in normalized_annotations:\n",
    "        normalized_annotations[region_id] = []\n",
    "    normalized_annotations[region_id].append(f\"{x:.17f} {y:.17f}\")\n",
    "\n",
    "# Create the normalized formatted string\n",
    "normalized_output = \"\"\n",
    "for region_id in sorted(normalized_annotations.keys()):\n",
    "    normalized_output += f\"{region_id} \" + \" \".join(normalized_annotations[region_id]) + \"\\n\"\n",
    "\n",
    "# Write the normalized output to a new file\n",
    "normalized_output_file_path = r'R:\\FIVE\\EXP\\FIV925\\SC_Mendeley\\Results\\Val on nissl\\normalized_yolo_annotations.txt'\n",
    "with open(normalized_output_file_path, 'w') as normalized_output_file:\n",
    "    normalized_output_file.write(normalized_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
