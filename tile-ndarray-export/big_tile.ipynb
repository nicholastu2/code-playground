{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torchvision:  0.17.2\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import socket\n",
    "import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from random import randint\n",
    "import re\n",
    "import imagecodecs\n",
    "import tifffile\n",
    "import tensorflow as tf\n",
    "from scipy.spatial import Voronoi, cKDTree\n",
    "from matplotlib.path import Path\n",
    "from rtree import index\n",
    "from ctypes.wintypes import INT\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, Point\n",
    "import torch, torchvision\n",
    "import colorsys\n",
    "\n",
    "print(\"torchvision: \", torchvision.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_by_id(point_region_id, total_ids):\n",
    "    hue = point_region_id / total_ids # Scale the hue by the number of unique IDs, wrapping around the hue circle\n",
    "    saturation = 0.9; value = 0.9  # Keep saturation and value high for bright colors\n",
    "    rgb = colorsys.hsv_to_rgb(hue, saturation, value)\n",
    "    r, g, b = (int(c * 255) for c in rgb)  # Convert to 0-255 scale for RGB colors\n",
    "    return (r << 16) | (g << 8) | b  # Combine into a single integer\n",
    "\n",
    "def int24_to_rgb(objID):\n",
    "    r = (objID >> 16) & 0xFF  # Extract the highest 8 bits\n",
    "    g = (objID >> 8) & 0xFF   # Extract the middle 8 bits\n",
    "    b = objID & 0xFF          # Extract the lowest 8 bits\n",
    "    return r, g, b\n",
    "\n",
    "def ellipse_points(cx, cy, rx, ry, n=8):\n",
    "    \"\"\"Generate n points along the ellipse centered at (cx, cy) with radii rx and ry.\"\"\"\n",
    "    angles = np.linspace(0, 2 * np.pi, n, endpoint=False)\n",
    "    points = [(cx + rx * np.cos(angle), cy + ry * np.sin(angle)) for angle in angles]\n",
    "    return points\n",
    "\n",
    "def draw_polygons(draw, polygons):\n",
    "    global globalID\n",
    "    for polygon in polygons:\n",
    "        if len(polygon) < 2:\n",
    "            continue\n",
    "        # color = get_color_by_id(i, len(polygons))\n",
    "        # draw.polygon(polygon, fill=i, outline='white')\n",
    "        globalID+=1\n",
    "        # there still aren't unique identifiers for each instance of a polygon\n",
    "        #   I wonder if this is because the conversion from 24 bit to 8 bit integers doesn't guarantee a unique set of 8 bit integers for each 24 bit integer \n",
    "        (r,g,b) = int24_to_rgb(globalID)\n",
    "        if (globalID == 300): print(globalID,r,g,b)\n",
    "        draw.polygon(polygon, fill=(r,g,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_model_path = r\"S:\\Phys\\FIV925 XSection\\Datasets\\Axons vs SCs\\01i5\\YO 384 0530 MAXI\\map75=0855192 YOLOv8n-seg map75=081193 idx=4 ep=24 btch=32 rnd=2840511\\weights\\best.pt\"\n",
    "model = YOLO(yolo_model_path)\n",
    "pred_height, pred_width = 384, 384\n",
    "test_rows = 2\n",
    "test_cols = 2\n",
    "iteration = 0\n",
    "scale_factor = 1\n",
    "globalID = 0\n",
    "maxArea = 10000\n",
    "dataset = \"Human Lung Cancer\"\n",
    "base_path = r\"R:\\FIVE\\EXP\\FIV925\\Additional Datasets\"\n",
    "ome_tiff_path = f\"{base_path}\\\\{dataset}\\\\morphology_mip.ome.tif\"\n",
    "use_entire_image = True\n",
    "\n",
    "image = tifffile.TiffFile(ome_tiff_path).asarray()\n",
    "image_data = image[::2, ::2]\n",
    "max_val_16bit = np.max(image_data)\n",
    "image_scaled = (image_data / max_val_16bit) * 255\n",
    "image_8bit = image_scaled.astype(np.uint8)\n",
    "\n",
    "# create image and resize\n",
    "og_image = Image.fromarray(image_8bit, 'L')\n",
    "new_width = int(og_image.width * scale_factor); new_height = int(og_image.height * scale_factor)\n",
    "image_resized = og_image.resize((new_width, new_height), Image.LANCZOS)\n",
    "image = np.array(image_resized)\n",
    "\n",
    "start_y = pred_height * 10\n",
    "start_x = pred_width * 10\n",
    "image_height_use = pred_height * test_rows\n",
    "image_width_use = pred_width * test_cols\n",
    "\n",
    "if use_entire_image:\n",
    "    start_y = 0\n",
    "    start_x = 0\n",
    "    image_height_use = image_resized.height + pred_height*2\n",
    "    image_width_use = image_resized.width + pred_width*2\n",
    "    \n",
    "\n",
    "big_array = np.zeros((image_width_use, image_height_use)).astype(np.int32)\n",
    "list_xywh = []\n",
    "maxValue = 0\n",
    "\n",
    "# as we're making predictions, we want a big array that's meant to 'contain' the whole image\n",
    "#   then insert the predictions into that big array\n",
    "# so here is where we go through the image as tiles and make the predictions\n",
    "tile_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FIVE\\anaconda3\\envs\\torch01\\lib\\site-packages\\torch\\nn\\modules\\module.py:1150: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\c10/cuda/CUDAAllocatorConfig.h:30.)\n",
      "  return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x384 (no detections), 9.5ms\n",
      "Speed: 3.0ms preprocess, 9.5ms inference, 15.5ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  1\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  2\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  3\n",
      "\n",
      "0: 384x384 (no detections), 13.1ms\n",
      "Speed: 1.0ms preprocess, 13.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  4\n",
      "\n",
      "0: 384x384 (no detections), 11.7ms\n",
      "Speed: 0.5ms preprocess, 11.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  5\n",
      "\n",
      "0: 384x384 (no detections), 9.6ms\n",
      "Speed: 1.0ms preprocess, 9.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  6\n",
      "\n",
      "0: 384x384 4 axons, 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 284.2ms postprocess per image at shape (1, 3, 384, 384)\n",
      "4\n",
      "ERRRORORORORORORORO\n",
      "iteration:  7\n",
      "\n",
      "0: 384x384 (no detections), 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  8\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  9\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  10\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  11\n",
      "\n",
      "0: 384x384 1 axon, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "5\n",
      "ERRRORORORORORORORO\n",
      "iteration:  12\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  13\n",
      "\n",
      "0: 384x384 1 nuclei, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "6\n",
      "ERRRORORORORORORORO\n",
      "iteration:  14\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  15\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  16\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  17\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  18\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  19\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  20\n",
      "\n",
      "0: 384x384 (no detections), 9.1ms\n",
      "Speed: 1.0ms preprocess, 9.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  21\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  22\n",
      "\n",
      "0: 384x384 (no detections), 13.0ms\n",
      "Speed: 0.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  23\n",
      "\n",
      "0: 384x384 (no detections), 9.1ms\n",
      "Speed: 1.1ms preprocess, 9.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  24\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  25\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  26\n",
      "\n",
      "0: 384x384 (no detections), 10.0ms\n",
      "Speed: 0.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 384)\n",
      "0\n",
      "ERRRORORORORORORORO\n",
      "iteration:  27\n",
      "\n",
      "0: 384x256 (no detections), 147.3ms\n",
      "Speed: 0.0ms preprocess, 147.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 256)\n",
      "0\n",
      "ERRRORORORORORORORO\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (384,384) into shape (384,249)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERRRORORORORORORORO\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m---> 58\u001b[0m         \u001b[43mbig_array\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstart_y\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstart_y\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstart_x\u001b[49m\u001b[43m:\u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mstart_x\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m int_array\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miteration: \u001b[39m\u001b[38;5;124m\"\u001b[39m, iteration)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiggest value in big_array:\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmax(big_array))\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (384,384) into shape (384,249)"
     ]
    }
   ],
   "source": [
    "for i in range(start_x, image_width_use + start_x, pred_width): # section_minx, section_maxx\n",
    "    for j in range(start_y, image_height_use + start_y, pred_height): # section_miny, section_maxy\n",
    "        iteration += 1\n",
    "        tile = image[i:i+pred_width, j:j+pred_height]\n",
    "        \n",
    "        tile_id += 1\n",
    "        \n",
    "        if tile.shape[0] == 0 or tile.shape[1] == 0:\n",
    "            continue  # Skip tiles that have no width or height\n",
    "        tile_as_img = Image.fromarray(tile, 'L')\n",
    "        predictions = model.predict(tile_as_img, show=False, max_det=3000) # can we pass an np array?\n",
    "        \n",
    "        result = predictions[0]\n",
    "        # draw masks onto blank image\n",
    "        if result.masks is not None:\n",
    "            polygons = result.masks.xy\n",
    "        else:\n",
    "            if result.boxes is not None:\n",
    "                ## Ellipse Version\n",
    "                polygons = []\n",
    "                for (cx, cy, w, h) in result.boxes.xywh:\n",
    "                    rx = w / 2\n",
    "                    ry = h / 2\n",
    "                    ellipse = ellipse_points(cx, cy, rx, ry, 8)\n",
    "                    if (w*h)>maxArea: continue\n",
    "                    polygons.append(ellipse)\n",
    "                \n",
    "                ## Bounding Box Version\n",
    "                # xyxy = result.boxes.xyxy\n",
    "                # for (x1, y1, x2, y2) in xyxy:\n",
    "                #     polygon = [(x1, y1), (x2, y1), (x2, y2), (x1, y2)]\n",
    "                #     polygons.append(polygon)\n",
    "            else:\n",
    "                print(\"No Polygons or Boxes\"); continue\n",
    "        \n",
    "        blank_tile = np.zeros((pred_width, pred_height,3))\n",
    "        blank_tile_as_img = Image.fromarray(blank_tile,\"RGB\")\n",
    "        draw_tile = ImageDraw.Draw(blank_tile_as_img) \n",
    "        draw_polygons(draw_tile, polygons)\n",
    "        rgb_array = np.array(blank_tile_as_img).astype(np.int32)\n",
    "        #rgb_array = rgb_array.astype(np.uint32)\n",
    "        int_array = np.zeros((pred_width, pred_height), dtype=np.int32)\n",
    "        int_array = ((rgb_array[:,:,0] << 16) | (rgb_array[:,:,1] << 8) | rgb_array[:,:,2])\n",
    "        currentMax = np.max(int_array)\n",
    "        print(currentMax)\n",
    "        if (currentMax > maxValue): maxValue = currentMax\n",
    "        \n",
    "        # need a new version of image_array where we decode the 3 channels into 1 channel\n",
    "        # ok I see the issue, we can only draw the polygons on the PIL image, and I don't know a way to draw them with different values\n",
    "        \n",
    "        # big_array[i:i - start_y, j:j - start_x] = image_array\n",
    "        try:\n",
    "            if int_array[0] > i-start_y:i-start_y+tile.shape[0] or int_array[1] > tile.shape[1]\n",
    "            big_array[i-start_y:i-start_y+tile.shape[0] , j-start_x:j - start_x+tile.shape[1]] = int_array\n",
    "        except:\n",
    "            print(\"ERRRORORORORORORORO\")\n",
    "            pass\n",
    "        big_array[i-start_y:i-start_y+tile.shape[0] , j-start_x:j - start_x+tile.shape[1]] = int_array\n",
    "        \n",
    "        print(\"iteration: \", iteration)\n",
    "        \n",
    "print(\"biggest value in big_array:\", np.max(big_array))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
